{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Douglas\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Douglas\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Douglas\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Douglas\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Douglas\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Douglas\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Douglas\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Douglas\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Douglas\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Douglas\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Douglas\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Douglas\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = base.drop('Forma de onda', axis=1) # atributos previsores\n",
    "y = base.iloc[:,-1] # pegando a ultima coluna para saber qual a classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "onehot = OneHotEncoder(categories = 'auto')\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.values.reshape(-1,1)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = onehot.fit_transform(y).toarray()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_treinamento, x_teste, y_treinamento, y_teste = train_test_split(x, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60, 100), (18, 100), (60, 3), (18, 3))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, x_teste.shape, y.shape, y_teste.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neuronios_entrada = x.shape[1]\n",
    "neuronios_entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neuronios_oculta1 = int((neuronios_entrada + y.shape[1])/2)\n",
    "neuronios_oculta1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuronios_oculta2 = neuronios_oculta1\n",
    "neuronios_oculta3 = neuronios_oculta1\n",
    "neuronios_oculta4 = neuronios_oculta1\n",
    "neuronios_oculta5 = neuronios_oculta1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neuronios_saida = y.shape[1]\n",
    "neuronios_saida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100 -> 51 -> 51 -> 51 -> 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'oculta1': <tf.Variable 'Variable_8:0' shape=(100, 51) dtype=float32_ref>,\n",
       " 'oculta2': <tf.Variable 'Variable_9:0' shape=(51, 51) dtype=float32_ref>,\n",
       " 'oculta3': <tf.Variable 'Variable_10:0' shape=(51, 51) dtype=float32_ref>,\n",
       " 'oculta4': <tf.Variable 'Variable_11:0' shape=(51, 51) dtype=float32_ref>,\n",
       " 'oculta5': <tf.Variable 'Variable_12:0' shape=(51, 51) dtype=float32_ref>,\n",
       " 'saida': <tf.Variable 'Variable_13:0' shape=(51, 3) dtype=float32_ref>}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = {'oculta1': tf.Variable(tf.random_normal([neuronios_entrada, neuronios_oculta1])),\n",
    "     'oculta2': tf.Variable(tf.random_normal([neuronios_oculta1, neuronios_oculta2])),\n",
    "     'oculta3': tf.Variable(tf.random_normal([neuronios_oculta2, neuronios_oculta3])),\n",
    "     'oculta4': tf.Variable(tf.random_normal([neuronios_oculta3, neuronios_oculta4])),\n",
    "     'oculta5': tf.Variable(tf.random_normal([neuronios_oculta4, neuronios_oculta5])),\n",
    "     'saida': tf.Variable(tf.random_normal([neuronios_oculta5, neuronios_saida]))}\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'oculta1': <tf.Variable 'Variable_14:0' shape=(51,) dtype=float32_ref>,\n",
       " 'oculta2': <tf.Variable 'Variable_15:0' shape=(51,) dtype=float32_ref>,\n",
       " 'oculta3': <tf.Variable 'Variable_16:0' shape=(51,) dtype=float32_ref>,\n",
       " 'oculta4': <tf.Variable 'Variable_17:0' shape=(51,) dtype=float32_ref>,\n",
       " 'oculta5': <tf.Variable 'Variable_18:0' shape=(51,) dtype=float32_ref>,\n",
       " 'saida': <tf.Variable 'Variable_19:0' shape=(3,) dtype=float32_ref>}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = {'oculta1': tf.Variable(tf.random_normal([neuronios_oculta1])),\n",
    "     'oculta2': tf.Variable(tf.random_normal([neuronios_oculta2])),\n",
    "     'oculta3': tf.Variable(tf.random_normal([neuronios_oculta3])),\n",
    "     'oculta4': tf.Variable(tf.random_normal([neuronios_oculta4])),\n",
    "     'oculta5': tf.Variable(tf.random_normal([neuronios_oculta5])),\n",
    "     'saida': tf.Variable(tf.random_normal([neuronios_saida]))}\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "xph = tf.placeholder('float', [None, neuronios_entrada])\n",
    "yph = tf.placeholder('float', [None, neuronios_saida])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(x, w, bias):\n",
    "    camada_oculta1 = tf.nn.relu(tf.add(tf.matmul(x, w['oculta1']), b['oculta1']))\n",
    "    camada_oculta2 = tf.nn.relu(tf.add(tf.matmul(camada_oculta1, w['oculta2']), b['oculta2']))\n",
    "    camada_oculta3 = tf.nn.relu(tf.add(tf.matmul(camada_oculta2, w['oculta3']), b['oculta3']))\n",
    "    camada_oculta4 = tf.nn.relu(tf.add(tf.matmul(camada_oculta2, w['oculta5']), b['oculta4']))\n",
    "    camada_oculta5 = tf.nn.relu(tf.add(tf.matmul(camada_oculta2, w['oculta5']), b['oculta5']))\n",
    "    camada_saida = tf.add(tf.matmul(camada_oculta3, w['saida']), b['saida'])\n",
    "    return camada_saida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = mlp(xph, w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "erro = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = modelo, labels = yph))\n",
    "otimizador = tf.train.AdamOptimizer(learning_rate = 0.0001).minimize(erro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 3\n",
    "batch_total = int(len(x_treinamento) / batch_size)\n",
    "batch_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[    Amostra 1  Amostra 2  Amostra 3  Amostra 4  Amostra 5  Amostra 6  \\\n",
       " 11        0.0      0.204      0.407      0.606      0.800      0.989   \n",
       " 9         0.0      1.395      2.785      4.164      5.525      6.865   \n",
       " 36        0.0      1.700      3.400      5.100      6.800      8.500   \n",
       " \n",
       "     Amostra 7  Amostra 8  Amostra 9  Amostra 10  ...  Amostra 91  Amostra 92  \\\n",
       " 11      1.169      1.340      1.501       1.649  ...       2.277       2.239   \n",
       " 9       8.177      9.455     10.696      11.894  ...     -11.894     -10.696   \n",
       " 36     10.200     11.900     13.600      15.300  ...      17.000      18.700   \n",
       " \n",
       "     Amostra 93  Amostra 94  Amostra 95  Amostra 96  Amostra 97  Amostra 98  \\\n",
       " 11       2.183       2.110       2.020       1.915       1.794       1.660   \n",
       " 9       -9.455      -8.177      -6.865      -5.525      -4.164      -2.785   \n",
       " 36      20.400      22.100      23.800      25.500      27.200      28.900   \n",
       " \n",
       "     Amostra 99  Amostra 100  \n",
       " 11       1.512        1.352  \n",
       " 9       -1.395        0.000  \n",
       " 36      30.600       32.300  \n",
       " \n",
       " [3 rows x 100 columns],\n",
       "     Amostra 1  Amostra 2  Amostra 3  Amostra 4  Amostra 5  Amostra 6  \\\n",
       " 4         0.0      0.634      1.266      1.893      2.511      3.120   \n",
       " 35        0.0      0.616      1.231      1.847      2.462      3.078   \n",
       " 20       -1.0     -0.900     -0.800     -0.700     -0.600     -0.500   \n",
       " \n",
       "     Amostra 7  Amostra 8  Amostra 9  Amostra 10  ...  Amostra 91  Amostra 92  \\\n",
       " 4       3.717      4.298      4.862       5.406  ...      -5.406      -4.862   \n",
       " 35      3.694      4.309      4.925       5.540  ...       6.156       6.772   \n",
       " 20     -0.400     -0.300     -0.200      -0.100  ...       0.000       0.100   \n",
       " \n",
       "     Amostra 93  Amostra 94  Amostra 95  Amostra 96  Amostra 97  Amostra 98  \\\n",
       " 4       -4.298      -3.717      -3.120      -2.511      -1.893      -1.266   \n",
       " 35       7.387       8.003       8.618       9.234       9.850      10.465   \n",
       " 20       0.200       0.300       0.400       0.500       0.600       0.700   \n",
       " \n",
       "     Amostra 99  Amostra 100  \n",
       " 4       -0.634        0.000  \n",
       " 35      11.081       11.696  \n",
       " 20       0.800        0.900  \n",
       " \n",
       " [3 rows x 100 columns],\n",
       "     Amostra 1  Amostra 2  Amostra 3  Amostra 4  Amostra 5  Amostra 6  \\\n",
       " 23        0.0      0.400      0.800       1.20      1.600      2.000   \n",
       " 6         0.0      0.888      1.772       2.65      3.516      4.368   \n",
       " 26        0.0      0.700      1.400       2.10      2.800      3.500   \n",
       " \n",
       "     Amostra 7  Amostra 8  Amostra 9  Amostra 10  ...  Amostra 91  Amostra 92  \\\n",
       " 23      2.400      2.800      3.200       3.600  ...       4.000       4.400   \n",
       " 6       5.203      6.017      6.807       7.569  ...      -7.569      -6.807   \n",
       " 26      4.200      4.900      5.600       6.300  ...       7.000       7.700   \n",
       " \n",
       "     Amostra 93  Amostra 94  Amostra 95  Amostra 96  Amostra 97  Amostra 98  \\\n",
       " 23       4.800       5.200       5.600       6.000        6.40       6.800   \n",
       " 6       -6.017      -5.203      -4.368      -3.516       -2.65      -1.772   \n",
       " 26       8.400       9.100       9.800      10.500       11.20      11.900   \n",
       " \n",
       "     Amostra 99  Amostra 100  \n",
       " 23       7.200          7.6  \n",
       " 6       -0.888          0.0  \n",
       " 26      12.600         13.3  \n",
       " \n",
       " [3 rows x 100 columns],\n",
       "     Amostra 1  Amostra 2  Amostra 3  Amostra 4  Amostra 5  Amostra 6  \\\n",
       " 32        0.0       0.35        0.7       1.05        1.4       1.75   \n",
       " 51        2.8       2.80        2.8       2.80        2.8       2.80   \n",
       " 55        6.5       6.50        6.5       6.50        6.5       6.50   \n",
       " \n",
       "     Amostra 7  Amostra 8  Amostra 9  Amostra 10  ...  Amostra 91  Amostra 92  \\\n",
       " 32        2.1       2.45        2.8        3.15  ...         3.5        3.85   \n",
       " 51        2.8       2.80        2.8        2.80  ...        -2.8       -2.80   \n",
       " 55        6.5       6.50        6.5        6.50  ...        -6.5       -6.50   \n",
       " \n",
       "     Amostra 93  Amostra 94  Amostra 95  Amostra 96  Amostra 97  Amostra 98  \\\n",
       " 32         4.2        4.55         4.9        5.25         5.6        5.95   \n",
       " 51        -2.8       -2.80        -2.8       -2.80        -2.8       -2.80   \n",
       " 55        -6.5       -6.50        -6.5       -6.50        -6.5       -6.50   \n",
       " \n",
       "     Amostra 99  Amostra 100  \n",
       " 32         6.3         6.65  \n",
       " 51        -2.8        -2.80  \n",
       " 55        -6.5        -6.50  \n",
       " \n",
       " [3 rows x 100 columns],\n",
       "     Amostra 1  Amostra 2  Amostra 3  Amostra 4  Amostra 5  Amostra 6  \\\n",
       " 37       0.00       1.80       3.60       5.40       7.20       9.00   \n",
       " 58       9.54       9.54       9.54       9.54       9.54       9.54   \n",
       " 38       0.00       0.95       1.90       2.85       3.80       4.75   \n",
       " \n",
       "     Amostra 7  Amostra 8  Amostra 9  Amostra 10  ...  Amostra 91  Amostra 92  \\\n",
       " 37      10.80      12.60      14.40       16.20  ...       18.00       19.80   \n",
       " 58       9.54       9.54       9.54        9.54  ...       -9.54       -9.54   \n",
       " 38       5.70       6.65       7.60        8.55  ...        9.50       10.45   \n",
       " \n",
       "     Amostra 93  Amostra 94  Amostra 95  Amostra 96  Amostra 97  Amostra 98  \\\n",
       " 37       21.60       23.40       25.20       27.00       28.80       30.60   \n",
       " 58       -9.54        9.54        9.54        9.54        9.54        9.54   \n",
       " 38       11.40       12.35       13.30       14.25       15.20       16.15   \n",
       " \n",
       "     Amostra 99  Amostra 100  \n",
       " 37       32.40        34.20  \n",
       " 58        9.54         9.54  \n",
       " 38       17.10        18.05  \n",
       " \n",
       " [3 rows x 100 columns],\n",
       "     Amostra 1  Amostra 2  Amostra 3  Amostra 4  Amostra 5  Amostra 6  \\\n",
       " 53       4.90      4.900      4.900      4.900      4.900      4.900   \n",
       " 13       0.00      4.817      7.759      7.678      4.607     -0.258   \n",
       " 57       8.33      8.330      8.330      8.330      8.330      8.330   \n",
       " \n",
       "     Amostra 7  Amostra 8  Amostra 9  Amostra 10  ...  Amostra 91  Amostra 92  \\\n",
       " 53      4.900      4.900      -4.90      -4.900  ...       4.900        4.90   \n",
       " 13     -5.023     -7.831      -7.59      -4.393  ...       4.393        7.59   \n",
       " 57      8.330      8.330       8.33      -8.330  ...       8.330        8.33   \n",
       " \n",
       "     Amostra 93  Amostra 94  Amostra 95  Amostra 96  Amostra 97  Amostra 98  \\\n",
       " 53       4.900      -4.900      -4.900      -4.900      -4.900      -4.900   \n",
       " 13       7.831       5.023       0.258      -4.607      -7.678      -7.759   \n",
       " 57       8.330      -8.330      -8.330      -8.330      -8.330      -8.330   \n",
       " \n",
       "     Amostra 99  Amostra 100  \n",
       " 53      -4.900        -4.90  \n",
       " 13      -4.817        -0.00  \n",
       " 57      -8.330        -8.33  \n",
       " \n",
       " [3 rows x 100 columns],\n",
       "     Amostra 1  Amostra 2  Amostra 3  Amostra 4  Amostra 5  Amostra 6  \\\n",
       " 24        0.0      0.500      1.000      1.500      2.000      2.500   \n",
       " 43        4.0      4.000      4.000      4.000      4.000      4.000   \n",
       " 12        0.0      0.308      0.614      0.917      1.215      1.506   \n",
       " \n",
       "     Amostra 7  Amostra 8  Amostra 9  Amostra 10  ...  Amostra 91  Amostra 92  \\\n",
       " 24       3.00      3.500      4.000       4.500  ...       5.000       5.500   \n",
       " 43       4.00      4.000      4.000       4.000  ...      -4.000      -4.000   \n",
       " 12       1.79      2.063      2.326       2.577  ...       1.189       1.481   \n",
       " \n",
       "     Amostra 93  Amostra 94  Amostra 95  Amostra 96  Amostra 97  Amostra 98  \\\n",
       " 24       6.000        6.50       7.000       7.500       8.000       8.500   \n",
       " 43      -4.000       -4.00      -4.000      -4.000      -4.000      -4.000   \n",
       " 12       1.765        2.04       2.304       2.556       2.794       3.017   \n",
       " \n",
       "     Amostra 99  Amostra 100  \n",
       " 24       9.000        9.500  \n",
       " 43      -4.000       -4.000  \n",
       " 12       3.224        3.414  \n",
       " \n",
       " [3 rows x 100 columns],\n",
       "     Amostra 1  Amostra 2  Amostra 3  Amostra 4  Amostra 5  Amostra 6  \\\n",
       " 18        0.0      1.277      2.550      3.812      5.058      6.284   \n",
       " 0         0.0      0.063      0.127      0.189      0.251      0.312   \n",
       " 27        0.0      0.800      1.600      2.400      3.200      4.000   \n",
       " \n",
       "     Amostra 7  Amostra 8  Amostra 9  Amostra 10  ...  Amostra 91  Amostra 92  \\\n",
       " 18      7.485      8.656      9.792      10.889  ...     -10.889      -9.792   \n",
       " 0       0.372      0.430      0.486       0.541  ...      -0.541      -0.486   \n",
       " 27      4.800      5.600      6.400       7.200  ...       8.000       8.800   \n",
       " \n",
       "     Amostra 93  Amostra 94  Amostra 95  Amostra 96  Amostra 97  Amostra 98  \\\n",
       " 18      -8.656      -7.485      -6.284      -5.058      -3.812      -2.550   \n",
       " 0       -0.430      -0.372      -0.312      -0.251      -0.189      -0.127   \n",
       " 27       9.600      10.400      11.200      12.000      12.800      13.600   \n",
       " \n",
       "     Amostra 99  Amostra 100  \n",
       " 18      -1.277          0.0  \n",
       " 0       -0.063          0.0  \n",
       " 27      14.400         15.2  \n",
       " \n",
       " [3 rows x 100 columns],\n",
       "     Amostra 1  Amostra 2  Amostra 3  Amostra 4  Amostra 5  Amostra 6  \\\n",
       " 1         0.0      0.127      0.253      0.379      0.502      0.624   \n",
       " 41        2.0      2.000      2.000      2.000      2.000      2.000   \n",
       " 52        3.5      3.500      3.500      3.500      3.500      3.500   \n",
       " \n",
       "     Amostra 7  Amostra 8  Amostra 9  Amostra 10  ...  Amostra 91  Amostra 92  \\\n",
       " 1       0.743       0.86      0.972       1.081  ...      -1.081      -0.972   \n",
       " 41      2.000       2.00      2.000       2.000  ...      -2.000      -2.000   \n",
       " 52      3.500       3.50      3.500       3.500  ...      -3.500      -3.500   \n",
       " \n",
       "     Amostra 93  Amostra 94  Amostra 95  Amostra 96  Amostra 97  Amostra 98  \\\n",
       " 1        -0.86      -0.743      -0.624      -0.502      -0.379      -0.253   \n",
       " 41       -2.00      -2.000      -2.000      -2.000      -2.000      -2.000   \n",
       " 52       -3.50      -3.500      -3.500      -3.500      -3.500      -3.500   \n",
       " \n",
       "     Amostra 99  Amostra 100  \n",
       " 1       -0.127          0.0  \n",
       " 41      -2.000         -2.0  \n",
       " 52      -3.500         -3.5  \n",
       " \n",
       " [3 rows x 100 columns],\n",
       "     Amostra 1  Amostra 2  Amostra 3  Amostra 4  Amostra 5  Amostra 6  \\\n",
       " 33        0.0      4.400      8.800     13.200     17.600     22.000   \n",
       " 49       10.0     10.000     10.000     10.000     10.000     10.000   \n",
       " 16        0.0      5.527     10.261     13.526     14.853     14.052   \n",
       " \n",
       "     Amostra 7  Amostra 8  Amostra 9  Amostra 10  ...  Amostra 91  Amostra 92  \\\n",
       " 33     26.400     30.800     35.200      39.600  ...      44.000      48.400   \n",
       " 49     10.000     10.000     10.000      10.000  ...     -10.000     -10.000   \n",
       " 16     11.238      6.814      1.413      -4.189  ...       4.189      -1.413   \n",
       " \n",
       "     Amostra 93  Amostra 94  Amostra 95  Amostra 96  Amostra 97  Amostra 98  \\\n",
       " 33      52.800      57.200      61.600      66.000      70.400      74.800   \n",
       " 49     -10.000     -10.000     -10.000     -10.000     -10.000     -10.000   \n",
       " 16      -6.814     -11.238     -14.052     -14.853     -13.526     -10.261   \n",
       " \n",
       "     Amostra 99  Amostra 100  \n",
       " 33      79.200         83.6  \n",
       " 49     -10.000        -10.0  \n",
       " 16      -5.527         -0.0  \n",
       " \n",
       " [3 rows x 100 columns],\n",
       "     Amostra 1  Amostra 2  Amostra 3  Amostra 4  Amostra 5  Amostra 6  \\\n",
       " 45       6.00      6.000      6.000      6.000      6.000      6.000   \n",
       " 5        0.00      0.761      1.519      2.271      3.014      3.744   \n",
       " 59      10.54     10.540     10.540     10.540     10.540     10.540   \n",
       " \n",
       "     Amostra 7  Amostra 8  Amostra 9  Amostra 10  ...  Amostra 91  Amostra 92  \\\n",
       " 45       6.00      6.000      6.000       6.000  ...      -6.000      -6.000   \n",
       " 5        4.46      5.158      5.834       6.488  ...      -6.488      -5.834   \n",
       " 59      10.54     10.540     10.540     -10.540  ...      10.540      10.540   \n",
       " \n",
       "     Amostra 93  Amostra 94  Amostra 95  Amostra 96  Amostra 97  Amostra 98  \\\n",
       " 45      -6.000       -6.00      -6.000      -6.000      -6.000      -6.000   \n",
       " 5       -5.158       -4.46      -3.744      -3.014      -2.271      -1.519   \n",
       " 59      10.540       10.54      10.540      10.540      10.540      10.540   \n",
       " \n",
       "     Amostra 99  Amostra 100  \n",
       " 45      -6.000        -6.00  \n",
       " 5       -0.761         0.00  \n",
       " 59      10.540       -10.54  \n",
       " \n",
       " [3 rows x 100 columns],\n",
       "     Amostra 1  Amostra 2  Amostra 3  Amostra 4  Amostra 5  Amostra 6  \\\n",
       " 21        0.0      0.200      0.400       0.60       0.80      1.000   \n",
       " 15        0.0      1.033      2.059       3.07       4.06      5.021   \n",
       " 22        0.0      0.300      0.600       0.90       1.20      1.500   \n",
       " \n",
       "     Amostra 7  Amostra 8  Amostra 9  Amostra 10  ...  Amostra 91  Amostra 92  \\\n",
       " 21      1.200      1.400      1.600       1.800  ...       2.000       2.200   \n",
       " 15      5.946      6.829      7.665       8.446  ...      11.802      12.051   \n",
       " 22      1.800      2.100      2.400       2.700  ...       3.000       3.300   \n",
       " \n",
       "     Amostra 93  Amostra 94  Amostra 95  Amostra 96  Amostra 97  Amostra 98  \\\n",
       " 21       2.400       2.600       2.800       3.000       3.200       3.400   \n",
       " 15      12.215      12.293      12.284      12.188      12.006      11.739   \n",
       " 22       3.600       3.900       4.200       4.500       4.800       5.100   \n",
       " \n",
       "     Amostra 99  Amostra 100  \n",
       " 21        3.60        3.800  \n",
       " 15       11.39       10.959  \n",
       " 22        5.40        5.700  \n",
       " \n",
       " [3 rows x 100 columns],\n",
       "     Amostra 1  Amostra 2  Amostra 3  Amostra 4  Amostra 5  Amostra 6  \\\n",
       " 46        7.0        7.0        7.0        7.0        7.0        7.0   \n",
       " 34        3.0        3.5        4.0        4.5        5.0        5.5   \n",
       " 56        7.2        7.2        7.2        7.2        7.2        7.2   \n",
       " \n",
       "     Amostra 7  Amostra 8  Amostra 9  Amostra 10  ...  Amostra 91  Amostra 92  \\\n",
       " 46        7.0        7.0        7.0         7.0  ...        -7.0        -7.0   \n",
       " 34        6.0        6.5        7.0         7.5  ...         8.0         8.5   \n",
       " 56        7.2        7.2        7.2         7.2  ...         7.2         7.2   \n",
       " \n",
       "     Amostra 93  Amostra 94  Amostra 95  Amostra 96  Amostra 97  Amostra 98  \\\n",
       " 46        -7.0        -7.0        -7.0        -7.0        -7.0        -7.0   \n",
       " 34         9.0         9.5        10.0        10.5        11.0        11.5   \n",
       " 56         7.2         7.2         7.2         7.2         7.2         7.2   \n",
       " \n",
       "     Amostra 99  Amostra 100  \n",
       " 46        -7.0         -7.0  \n",
       " 34        12.0         12.5  \n",
       " 56         7.2          7.2  \n",
       " \n",
       " [3 rows x 100 columns],\n",
       "     Amostra 1  Amostra 2  Amostra 3  Amostra 4  Amostra 5  Amostra 6  \\\n",
       " 28        0.0       0.90      1.800      2.700      3.600      4.500   \n",
       " 19        0.0       1.44      2.874      4.296      5.701      7.083   \n",
       " 42        3.0       3.00      3.000      3.000      3.000      3.000   \n",
       " \n",
       "     Amostra 7  Amostra 8  Amostra 9  Amostra 10  ...  Amostra 91  Amostra 92  \\\n",
       " 28      5.400      6.300      7.200       8.100  ...       9.000       9.900   \n",
       " 19      8.437      9.756     11.037      12.273  ...     -12.273     -11.037   \n",
       " 42      3.000      3.000      3.000       3.000  ...      -3.000      -3.000   \n",
       " \n",
       "     Amostra 93  Amostra 94  Amostra 95  Amostra 96  Amostra 97  Amostra 98  \\\n",
       " 28      10.800      11.700      12.600      13.500      14.400      15.300   \n",
       " 19      -9.756      -8.437      -7.083      -5.701      -4.296      -2.874   \n",
       " 42      -3.000      -3.000      -3.000      -3.000      -3.000      -3.000   \n",
       " \n",
       "     Amostra 99  Amostra 100  \n",
       " 28       16.20         17.1  \n",
       " 19       -1.44          0.0  \n",
       " 42       -3.00         -3.0  \n",
       " \n",
       " [3 rows x 100 columns]]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_batches = np.array_split(x_treinamento, batch_total)\n",
    "x_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época: 1 erro: 5794.033909388951\n",
      "Época: 501 erro: 1.5972428083646912e-05\n",
      "Época: 1001 erro: 4.427739673319918e-07\n",
      "Época: 1501 erro: 1.1353262964673507e-08\n",
      "Época: 2001 erro: 0.0\n",
      "Época: 2501 erro: 0.0\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoca in range(3000):\n",
    "        erro_medio = 0.0\n",
    "        batch_total = int(len(x_treinamento) / batch_size)\n",
    "        x_batches = np.array_split(x_treinamento, batch_total)\n",
    "        y_batches = np.array_split(y_treinamento, batch_total)\n",
    "        for i in range(batch_total):\n",
    "            x_batch, y_batch = x_batches[i], y_batches[i]\n",
    "            _, custo = sess.run([otimizador, erro], feed_dict = {xph: x_batch, yph: y_batch})\n",
    "            erro_medio += custo / batch_total\n",
    "        if epoca % 500 == 0:\n",
    "            print('Época: ' + str(epoca+1) + ' erro: '+ str(erro_medio))\n",
    "    w_final, b_final = sess.run([w,b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'oculta1': array([[-0.7120455 ,  0.4126431 , -1.377554  , ..., -0.05518564,\n",
       "          -1.19602   , -1.8617177 ],\n",
       "         [-0.46244308, -1.631183  , -0.55575544, ..., -0.97377676,\n",
       "          -1.1841421 , -1.2703358 ],\n",
       "         [-0.24545744, -0.7062301 ,  0.62997705, ...,  1.1979918 ,\n",
       "          -0.8323742 , -0.21008891],\n",
       "         ...,\n",
       "         [-0.8765789 ,  0.5189366 , -1.103395  , ...,  1.2131436 ,\n",
       "           1.1812949 ,  1.2904689 ],\n",
       "         [ 0.75006646, -2.4998932 ,  1.0228422 , ..., -0.11909717,\n",
       "          -0.14692935,  0.10767281],\n",
       "         [-0.2103482 ,  1.5156806 , -2.2196414 , ..., -0.5118653 ,\n",
       "           1.5998857 ,  0.00695339]], dtype=float32),\n",
       "  'oculta2': array([[-0.90367234,  0.9757227 , -1.1466354 , ..., -1.3217337 ,\n",
       "          -2.3740456 , -0.6189544 ],\n",
       "         [ 1.7222602 ,  0.09177739, -0.65288633, ..., -1.7852818 ,\n",
       "          -1.1059574 ,  0.2000637 ],\n",
       "         [ 1.1922356 ,  2.55233   ,  0.11464572, ..., -0.3162944 ,\n",
       "          -2.222422  ,  0.20370616],\n",
       "         ...,\n",
       "         [ 1.0170727 ,  0.50078875, -0.16631432, ...,  1.3353142 ,\n",
       "          -2.1207066 , -1.9177736 ],\n",
       "         [-2.2195318 ,  1.5069885 , -1.0228336 , ...,  1.0201906 ,\n",
       "           1.5225323 ,  0.7398392 ],\n",
       "         [ 0.36859745,  1.162293  ,  0.7713253 , ...,  1.5461599 ,\n",
       "           0.8267699 ,  0.38177463]], dtype=float32),\n",
       "  'oculta3': array([[ 0.28732726,  0.7151066 , -0.91672736, ...,  0.18793947,\n",
       "          -0.35554498, -0.7734787 ],\n",
       "         [-0.42234015,  0.69470525,  0.37379462, ..., -0.41072935,\n",
       "           0.7003385 , -0.5650682 ],\n",
       "         [-0.5530254 ,  0.20567693, -0.54847395, ...,  0.5957765 ,\n",
       "          -0.22338393, -0.12495467],\n",
       "         ...,\n",
       "         [-0.50604075,  0.5272988 ,  1.4675235 , ...,  0.40143362,\n",
       "          -0.38550028,  0.08721989],\n",
       "         [-0.268684  ,  0.17217337,  1.2002122 , ...,  0.30451608,\n",
       "           0.728065  , -1.0511187 ],\n",
       "         [-0.11997097,  0.19491227, -0.9009344 , ..., -0.41490775,\n",
       "          -0.5750473 , -1.9512976 ]], dtype=float32),\n",
       "  'saida': array([[-3.74297887e-01,  5.40385008e-01, -1.22472727e+00],\n",
       "         [ 4.22425628e-01,  9.56255138e-01, -9.01530802e-01],\n",
       "         [ 1.31321728e+00,  7.99851418e-01, -4.76271600e-01],\n",
       "         [ 1.00535870e+00, -6.51653647e-01, -1.12655573e-01],\n",
       "         [-2.10952401e-01,  7.63273776e-01, -3.61957885e-02],\n",
       "         [-1.09692347e+00, -1.16263580e+00,  1.09301627e+00],\n",
       "         [-3.68019640e-01,  8.31610262e-01,  5.28664410e-01],\n",
       "         [ 1.59556103e+00, -8.83397579e-01, -2.98032045e-01],\n",
       "         [-9.04649317e-01,  2.18833640e-01,  1.53977799e+00],\n",
       "         [-2.28830147e+00,  7.70680547e-01, -1.47772729e+00],\n",
       "         [ 9.07584965e-01,  6.07836127e-01, -8.68666530e-01],\n",
       "         [ 9.30324554e-01,  1.03194332e+00, -1.24009097e+00],\n",
       "         [ 8.15023363e-01,  3.19483340e-01,  2.16277575e+00],\n",
       "         [-3.13162059e-01, -1.80037498e-01,  7.87500292e-02],\n",
       "         [-1.14871168e+00, -1.89201772e-01, -6.96231946e-02],\n",
       "         [-3.53483647e-01, -1.13259745e+00, -1.59176779e+00],\n",
       "         [ 2.10702276e+00,  1.50817409e-01,  5.39775014e-01],\n",
       "         [-4.25821841e-02,  1.13564992e+00, -6.15829110e-01],\n",
       "         [-4.82301593e-01, -8.02187547e-02,  3.49692613e-01],\n",
       "         [ 1.49750650e-01, -7.63196409e-01,  2.20482005e-03],\n",
       "         [ 1.80011541e-01,  1.53390676e-01, -4.96826977e-01],\n",
       "         [ 3.83529872e-01,  8.10614705e-01,  6.04246795e-01],\n",
       "         [-1.96471140e-01,  5.70542634e-01, -1.39644891e-01],\n",
       "         [ 1.24990416e+00, -1.02366440e-01,  8.50411236e-01],\n",
       "         [-4.33168449e-02, -1.33435559e+00,  8.16483736e-01],\n",
       "         [-4.80979457e-02, -1.89908415e-01, -9.71877575e-01],\n",
       "         [-1.10540271e-01,  1.74729681e+00, -7.11955309e-01],\n",
       "         [-1.40292799e+00,  2.69552350e-01, -1.10018007e-01],\n",
       "         [ 9.45284128e-01,  1.57577857e-01, -7.67792091e-02],\n",
       "         [ 1.17177285e-01,  5.91963053e-01, -1.17676485e+00],\n",
       "         [ 3.14828455e-01,  2.13160753e+00, -5.13669848e-01],\n",
       "         [ 3.56644660e-01,  1.24666178e+00, -1.14431190e+00],\n",
       "         [ 5.91108203e-01,  6.72010064e-01,  1.45419824e+00],\n",
       "         [ 9.71843004e-01, -2.28603029e+00,  1.13184988e+00],\n",
       "         [ 2.24311858e-01,  2.16511345e+00, -2.25168538e+00],\n",
       "         [-1.76300645e-01,  1.02346087e+00, -3.91649216e-01],\n",
       "         [ 2.28753269e-01, -9.34159616e-04,  2.48198166e-01],\n",
       "         [ 2.78668553e-01, -9.97723639e-01,  7.94511020e-01],\n",
       "         [-1.36706340e+00, -3.02583314e-02, -6.38941348e-01],\n",
       "         [-3.27756032e-02,  2.04493141e+00,  2.83358455e-01],\n",
       "         [ 1.51920414e+00,  4.19279039e-01, -1.54188442e+00],\n",
       "         [-6.04033291e-01,  5.26596725e-01, -4.48836446e-01],\n",
       "         [-2.80547172e-01,  7.53686726e-01, -2.44618356e-01],\n",
       "         [-1.20757961e+00, -1.09611917e+00, -3.50425869e-01],\n",
       "         [ 2.81616688e-01, -1.07937634e-01,  9.24420953e-01],\n",
       "         [-1.17079401e+00, -1.30993032e+00,  5.20032406e-01],\n",
       "         [ 2.32829666e+00,  2.37399650e+00,  1.16437936e+00],\n",
       "         [-1.11506820e+00, -1.45967257e+00,  2.05184177e-01],\n",
       "         [ 2.17775807e-01,  6.22043550e-01, -1.32217777e+00],\n",
       "         [-1.97858536e+00,  5.86061954e-01,  1.70031166e+00],\n",
       "         [ 1.37110329e+00, -1.65398490e+00,  1.21394265e+00]], dtype=float32)},\n",
       " {'oculta1': array([ 0.07664868, -0.32084498,  1.1238681 ,  0.43557724,  0.40508938,\n",
       "          0.6717913 ,  1.2560476 , -0.12758757,  0.0992109 ,  0.4962534 ,\n",
       "         -0.33113277,  1.7516499 , -0.8345873 ,  1.085282  , -0.5983055 ,\n",
       "         -1.0304052 ,  0.55746   ,  0.65054184, -0.5952635 , -0.34783915,\n",
       "          0.61844206,  0.8108504 , -2.1913602 ,  0.1693313 ,  2.2627313 ,\n",
       "          1.1643283 , -1.5096802 ,  0.21588889,  0.43176666,  0.25775123,\n",
       "         -0.3401344 , -0.05199545, -1.6437131 , -0.62091714, -1.3202003 ,\n",
       "          0.835504  , -0.15866159,  0.4535802 ,  0.9789123 , -0.14667346,\n",
       "          2.0768757 , -0.06738957,  1.3963151 , -0.24539444, -1.4605087 ,\n",
       "         -1.1414154 , -0.70511293,  0.5182735 , -0.1466912 ,  0.17892559,\n",
       "         -0.18168508], dtype=float32),\n",
       "  'oculta2': array([-7.3719777e-02,  4.1265321e-01, -9.3770850e-01,  3.2730246e-01,\n",
       "          1.3471142e+00, -1.6906360e-01, -3.7865981e-01,  6.8446332e-01,\n",
       "          2.6204920e-01, -1.1987106e+00,  5.4502096e-02,  5.2478045e-01,\n",
       "         -1.3572387e-01, -8.7112442e-02, -1.2843702e+00,  8.1087416e-01,\n",
       "          2.0828141e-01,  5.3503335e-01,  4.4168943e-01,  2.3337852e-03,\n",
       "          8.8704872e-01, -1.7679956e+00, -1.0338431e-01, -3.3704504e-01,\n",
       "          1.5048839e+00, -3.9159521e-01, -2.8869331e-01,  1.9934324e+00,\n",
       "         -1.5384487e+00,  3.9486384e-01, -2.3388994e-01, -9.2478834e-02,\n",
       "          3.3487362e-01, -9.1334355e-01,  2.9204202e+00, -8.9643008e-01,\n",
       "          1.4463301e+00, -1.0094198e+00,  1.1833696e+00, -1.1353362e+00,\n",
       "         -5.5555356e-01, -9.7156984e-01,  8.8776302e-01,  1.0396773e+00,\n",
       "          2.9286125e-01, -1.5215410e+00, -1.1531078e+00, -1.0087806e+00,\n",
       "          1.1659451e+00,  1.2768728e+00, -7.4811864e-01], dtype=float32),\n",
       "  'oculta3': array([-0.89330286, -0.09281549, -1.5324606 , -0.674692  , -0.5783022 ,\n",
       "          0.8563302 , -0.3168556 ,  0.22527239, -0.91289705,  0.8965526 ,\n",
       "         -1.060772  , -0.48606968,  0.8941587 ,  0.13141605,  0.41364044,\n",
       "          0.8095083 ,  0.81746495, -0.28997335,  1.3772359 ,  0.4912937 ,\n",
       "          0.9635859 , -0.9123551 ,  0.96721685,  1.1138046 ,  1.3665262 ,\n",
       "          0.3904725 , -0.13879056, -1.3327346 , -1.092725  ,  0.48169896,\n",
       "          0.13825336, -1.2475065 , -0.7156135 , -0.93192273,  1.1309354 ,\n",
       "          0.52983856,  0.67646366, -0.7651418 ,  0.8567245 ,  0.23032175,\n",
       "          0.82190657, -0.33115023,  1.8879787 ,  0.21264471,  0.94638073,\n",
       "         -1.9478192 , -0.780209  ,  0.5423286 ,  0.78939676,  1.6482321 ,\n",
       "          0.63682055], dtype=float32),\n",
       "  'saida': array([ 0.8045548 , -1.505135  ,  0.38911474], dtype=float32)})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_final, b_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsoes_teste = mlp(xph, w_final, b_final)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    r1 = sess.run(previsoes_teste, feed_dict = {xph: x_teste})\n",
    "    r2 = sess.run(tf.nn.softmax(r1))\n",
    "    r3 = sess.run(tf.argmax(r2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   672.7305  ,    490.53607 ,    167.99634 ],\n",
       "       [  2041.7205  ,  -1831.8513  ,    582.8822  ],\n",
       "       [  1027.9618  ,   -795.5342  ,    307.3267  ],\n",
       "       [  -587.79865 ,   6342.9985  ,  -2120.1416  ],\n",
       "       [ -2413.9587  ,   4233.0044  , -10224.803   ],\n",
       "       [   644.9867  ,    280.6967  ,    212.9208  ],\n",
       "       [  4579.1147  ,  -4406.0327  ,   1298.8787  ],\n",
       "       [ -3288.9067  ,  -2057.4802  ,     51.451805],\n",
       "       [  5085.9565  ,  -4921.2324  ,   1442.8978  ],\n",
       "       [ -6054.096   ,  -3864.6306  ,     83.19866 ],\n",
       "       [  1228.3967  ,   1264.2947  ,    760.48785 ],\n",
       "       [  7523.9062  ,   4604.581   ,  -5033.8223  ],\n",
       "       [ -5362.805   ,  -3412.8433  ,     75.26358 ],\n",
       "       [   144.29019 ,   1403.6906  ,  -1529.9875  ],\n",
       "       [  2951.972   ,   3111.883   ,   2087.271   ],\n",
       "       [  4853.8745  ,   5126.465   ,   3524.9827  ],\n",
       "       [  -570.8729  ,   -272.73914 ,    -12.88292 ],\n",
       "       [  5091.622   ,   5378.293   ,   3704.7     ]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00],\n",
       "       [2.5687317e-16, 1.0000000e+00, 0.0000000e+00],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 0, 0, 2, 0, 2, 1, 0, 2, 1, 1, 1, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 0, 0, 2, 0, 2, 1, 2, 2, 2, 1, 1, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_teste2 = np.argmax(y_teste, 1)\n",
    "y_teste2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7222222222222222"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "taxa_acerto = accuracy_score(y_teste2, r3)\n",
    "taxa_acerto"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
