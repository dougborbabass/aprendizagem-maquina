{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Douglas\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Douglas\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Douglas\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Douglas\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Douglas\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Douglas\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Douglas\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Douglas\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Douglas\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Douglas\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Douglas\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Douglas\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = pd.read_csv('test.csv')\n",
    "base2 = pd.read_csv('test2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = base.drop('Forma de onda', axis=1) # atributos previsores\n",
    "x2 = base2.drop('Forma de onda', axis=1) # atributos previsores\n",
    "y = base.iloc[:,-1] # pegando a ultima coluna para saber qual a classe\n",
    "y2 = base.iloc[:,-1] # pegando a ultima coluna para saber qual a classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60,), (60,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "onehot = OneHotEncoder(categories = 'auto')\n",
    "y.shape, y2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60, 1), (60, 1))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.values.reshape(-1,1)\n",
    "y2 = y2.values.reshape(-1,1)\n",
    "y.shape, y2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.]]),\n",
       " array([[1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = onehot.fit_transform(y).toarray()\n",
    "y2 = onehot.fit_transform(y2).toarray()\n",
    "y, y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_treinamento, x_teste, y_treinamento, y_teste = train_test_split(x, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60, 100), (18, 100), (60, 3), (18, 3))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, x_teste.shape, y.shape, y_teste.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neuronios_entrada = x.shape[1]\n",
    "neuronios_entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neuronios_oculta = int((neuronios_entrada + y.shape[1])/2)\n",
    "neuronios_oculta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neuronios_saida = y.shape[1]\n",
    "neuronios_saida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'oculta': <tf.Variable 'Variable:0' shape=(100, 51) dtype=float32_ref>,\n",
       " 'saida': <tf.Variable 'Variable_1:0' shape=(51, 3) dtype=float32_ref>}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = {'oculta': tf.Variable(tf.random_normal([neuronios_entrada, neuronios_oculta])),\n",
    "     'saida': tf.Variable(tf.random_normal([neuronios_oculta, neuronios_saida]))}\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'oculta': <tf.Variable 'Variable_2:0' shape=(51,) dtype=float32_ref>,\n",
       " 'saida': <tf.Variable 'Variable_3:0' shape=(3,) dtype=float32_ref>}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = {'oculta': tf.Variable(tf.random_normal([neuronios_oculta])),\n",
    "     'saida': tf.Variable(tf.random_normal([neuronios_saida]))}\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "xph = tf.placeholder('float', [None, neuronios_entrada])\n",
    "yph = tf.placeholder('float', [None, neuronios_saida])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(x, w, bias):\n",
    "    camada_oculta = tf.add(tf.matmul(x, w['oculta']), b['oculta'])\n",
    "    camada_oculta_ativacao = tf.nn.relu(camada_oculta)\n",
    "    camada_saida = tf.add(tf.matmul(camada_oculta_ativacao, w['saida']), b['saida'])\n",
    "    return camada_saida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = mlp(xph, w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "erro = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = modelo, labels = yph))\n",
    "otimizador = tf.train.AdamOptimizer(learning_rate = 0.0001).minimize(erro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_total = int(len(x_treinamento) / batch_size)\n",
    "batch_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[    Amostra 1  Amostra 2  Amostra 3  Amostra 4  Amostra 5  Amostra 6  \\\n",
       " 53        4.9      4.900      4.900      4.900      4.900      4.900   \n",
       " 3         0.0      0.507      1.013      1.514      2.009      2.496   \n",
       " 28        0.0      0.900      1.800      2.700      3.600      4.500   \n",
       " 34        3.0      3.500      4.000      4.500      5.000      5.500   \n",
       " 12        0.0      0.308      0.614      0.917      1.215      1.506   \n",
       " \n",
       "     Amostra 7  Amostra 8  Amostra 9  Amostra 10  ...  Amostra 91  Amostra 92  \\\n",
       " 53      4.900      4.900     -4.900      -4.900  ...       4.900       4.900   \n",
       " 3       2.973      3.438      3.890       4.325  ...      -4.325      -3.890   \n",
       " 28      5.400      6.300      7.200       8.100  ...       9.000       9.900   \n",
       " 34      6.000      6.500      7.000       7.500  ...       8.000       8.500   \n",
       " 12      1.790      2.063      2.326       2.577  ...       1.189       1.481   \n",
       " \n",
       "     Amostra 93  Amostra 94  Amostra 95  Amostra 96  Amostra 97  Amostra 98  \\\n",
       " 53       4.900      -4.900      -4.900      -4.900      -4.900      -4.900   \n",
       " 3       -3.438      -2.973      -2.496      -2.009      -1.514      -1.013   \n",
       " 28      10.800      11.700      12.600      13.500      14.400      15.300   \n",
       " 34       9.000       9.500      10.000      10.500      11.000      11.500   \n",
       " 12       1.765       2.040       2.304       2.556       2.794       3.017   \n",
       " \n",
       "     Amostra 99  Amostra 100  \n",
       " 53      -4.900       -4.900  \n",
       " 3       -0.507        0.000  \n",
       " 28      16.200       17.100  \n",
       " 34      12.000       12.500  \n",
       " 12       3.224        3.414  \n",
       " \n",
       " [5 rows x 100 columns],\n",
       "     Amostra 1  Amostra 2  Amostra 3  Amostra 4  Amostra 5  Amostra 6  \\\n",
       " 54        5.7      5.700      5.700      5.700      5.700     -5.700   \n",
       " 14        0.0      3.214      6.107      8.390      9.835     10.299   \n",
       " 13        0.0      4.817      7.759      7.678      4.607     -0.258   \n",
       " 15        0.0      1.033      2.059      3.070      4.060      5.021   \n",
       " 35        0.0      0.616      1.231      1.847      2.462      3.078   \n",
       " \n",
       "     Amostra 7  Amostra 8  Amostra 9  Amostra 10  ...  Amostra 91  Amostra 92  \\\n",
       " 54     -5.700     -5.700     -5.700      -5.700  ...       5.700       5.700   \n",
       " 14      9.734      8.196      5.841       2.902  ...      -2.902      -5.841   \n",
       " 13     -5.023     -7.831     -7.590      -4.393  ...       4.393       7.590   \n",
       " 15      5.946      6.829      7.665       8.446  ...      11.802      12.051   \n",
       " 35      3.694      4.309      4.925       5.540  ...       6.156       6.772   \n",
       " \n",
       "     Amostra 93  Amostra 94  Amostra 95  Amostra 96  Amostra 97  Amostra 98  \\\n",
       " 54       5.700       5.700       5.700       5.700      -5.700      -5.700   \n",
       " 14      -8.196      -9.734     -10.299      -9.835      -8.390      -6.107   \n",
       " 13       7.831       5.023       0.258      -4.607      -7.678      -7.759   \n",
       " 15      12.215      12.293      12.284      12.188      12.006      11.739   \n",
       " 35       7.387       8.003       8.618       9.234       9.850      10.465   \n",
       " \n",
       "     Amostra 99  Amostra 100  \n",
       " 54      -5.700       -5.700  \n",
       " 14      -3.214       -0.000  \n",
       " 13      -4.817       -0.000  \n",
       " 15      11.390       10.959  \n",
       " 35      11.081       11.696  \n",
       " \n",
       " [5 rows x 100 columns],\n",
       "     Amostra 1  Amostra 2  Amostra 3  Amostra 4  Amostra 5  Amostra 6  \\\n",
       " 2         0.0      0.254      0.506      0.757      1.005      1.248   \n",
       " 0         0.0      0.063      0.127      0.189      0.251      0.312   \n",
       " 41        2.0      2.000      2.000      2.000      2.000      2.000   \n",
       " 46        7.0      7.000      7.000      7.000      7.000      7.000   \n",
       " \n",
       "     Amostra 7  Amostra 8  Amostra 9  Amostra 10  ...  Amostra 91  Amostra 92  \\\n",
       " 2       1.487      1.719      1.945       2.163  ...      -2.163      -1.945   \n",
       " 0       0.372      0.430      0.486       0.541  ...      -0.541      -0.486   \n",
       " 41      2.000      2.000      2.000       2.000  ...      -2.000      -2.000   \n",
       " 46      7.000      7.000      7.000       7.000  ...      -7.000      -7.000   \n",
       " \n",
       "     Amostra 93  Amostra 94  Amostra 95  Amostra 96  Amostra 97  Amostra 98  \\\n",
       " 2       -1.719      -1.487      -1.248      -1.005      -0.757      -0.506   \n",
       " 0       -0.430      -0.372      -0.312      -0.251      -0.189      -0.127   \n",
       " 41      -2.000      -2.000      -2.000      -2.000      -2.000      -2.000   \n",
       " 46      -7.000      -7.000      -7.000      -7.000      -7.000      -7.000   \n",
       " \n",
       "     Amostra 99  Amostra 100  \n",
       " 2       -0.254          0.0  \n",
       " 0       -0.063          0.0  \n",
       " 41      -2.000         -2.0  \n",
       " 46      -7.000         -7.0  \n",
       " \n",
       " [4 rows x 100 columns],\n",
       "     Amostra 1  Amostra 2  Amostra 3  Amostra 4  Amostra 5  Amostra 6  \\\n",
       " 51       2.80      2.800      2.800      2.800      2.800      2.800   \n",
       " 58       9.54      9.540      9.540      9.540      9.540      9.540   \n",
       " 31       0.00      0.233      0.466      0.699      0.932      1.165   \n",
       " 38       0.00      0.950      1.900      2.850      3.800      4.750   \n",
       " \n",
       "     Amostra 7  Amostra 8  Amostra 9  Amostra 10  ...  Amostra 91  Amostra 92  \\\n",
       " 51      2.800      2.800      2.800       2.800  ...       -2.80      -2.800   \n",
       " 58      9.540      9.540      9.540       9.540  ...       -9.54      -9.540   \n",
       " 31      1.398      1.631      1.864       2.097  ...        2.33       2.563   \n",
       " 38      5.700      6.650      7.600       8.550  ...        9.50      10.450   \n",
       " \n",
       "     Amostra 93  Amostra 94  Amostra 95  Amostra 96  Amostra 97  Amostra 98  \\\n",
       " 51      -2.800      -2.800      -2.800      -2.800      -2.800      -2.800   \n",
       " 58      -9.540       9.540       9.540       9.540       9.540       9.540   \n",
       " 31       2.796       3.029       3.262       3.495       3.728       3.961   \n",
       " 38      11.400      12.350      13.300      14.250      15.200      16.150   \n",
       " \n",
       "     Amostra 99  Amostra 100  \n",
       " 51      -2.800       -2.800  \n",
       " 58       9.540        9.540  \n",
       " 31       4.194        4.427  \n",
       " 38      17.100       18.050  \n",
       " \n",
       " [4 rows x 100 columns],\n",
       "     Amostra 1  Amostra 2  Amostra 3  Amostra 4  Amostra 5  Amostra 6  \\\n",
       " 36       0.00      1.700      3.400      5.100       6.80      8.500   \n",
       " 11       0.00      0.204      0.407      0.606       0.80      0.989   \n",
       " 29       0.00      1.000      2.000      3.000       4.00      5.000   \n",
       " 50       1.35      1.350      1.350      1.350       1.35      1.350   \n",
       " \n",
       "     Amostra 7  Amostra 8  Amostra 9  Amostra 10  ...  Amostra 91  Amostra 92  \\\n",
       " 36     10.200      11.90     13.600      15.300  ...      17.000      18.700   \n",
       " 11      1.169       1.34      1.501       1.649  ...       2.277       2.239   \n",
       " 29      6.000       7.00      8.000       9.000  ...      10.000      11.000   \n",
       " 50      1.350      -1.35     -1.350      -1.350  ...       1.350       1.350   \n",
       " \n",
       "     Amostra 93  Amostra 94  Amostra 95  Amostra 96  Amostra 97  Amostra 98  \\\n",
       " 36      20.400       22.10       23.80      25.500      27.200       28.90   \n",
       " 11       2.183        2.11        2.02       1.915       1.794        1.66   \n",
       " 29      12.000       13.00       14.00      15.000      16.000       17.00   \n",
       " 50       1.350        1.35       -1.35      -1.350      -1.350       -1.35   \n",
       " \n",
       "     Amostra 99  Amostra 100  \n",
       " 36      30.600       32.300  \n",
       " 11       1.512        1.352  \n",
       " 29      18.000       19.000  \n",
       " 50      -1.350       -1.350  \n",
       " \n",
       " [4 rows x 100 columns],\n",
       "     Amostra 1  Amostra 2  Amostra 3  Amostra 4  Amostra 5  Amostra 6  \\\n",
       " 19        0.0      1.440      2.874      4.296      5.701      7.083   \n",
       " 1         0.0      0.127      0.253      0.379      0.502      0.624   \n",
       " 33        0.0      4.400      8.800     13.200     17.600     22.000   \n",
       " 6         0.0      0.888      1.772      2.650      3.516      4.368   \n",
       " \n",
       "     Amostra 7  Amostra 8  Amostra 9  Amostra 10  ...  Amostra 91  Amostra 92  \\\n",
       " 19      8.437      9.756     11.037      12.273  ...     -12.273     -11.037   \n",
       " 1       0.743      0.860      0.972       1.081  ...      -1.081      -0.972   \n",
       " 33     26.400     30.800     35.200      39.600  ...      44.000      48.400   \n",
       " 6       5.203      6.017      6.807       7.569  ...      -7.569      -6.807   \n",
       " \n",
       "     Amostra 93  Amostra 94  Amostra 95  Amostra 96  Amostra 97  Amostra 98  \\\n",
       " 19      -9.756      -8.437      -7.083      -5.701      -4.296      -2.874   \n",
       " 1       -0.860      -0.743      -0.624      -0.502      -0.379      -0.253   \n",
       " 33      52.800      57.200      61.600      66.000      70.400      74.800   \n",
       " 6       -6.017      -5.203      -4.368      -3.516      -2.650      -1.772   \n",
       " \n",
       "     Amostra 99  Amostra 100  \n",
       " 19      -1.440          0.0  \n",
       " 1       -0.127          0.0  \n",
       " 33      79.200         83.6  \n",
       " 6       -0.888          0.0  \n",
       " \n",
       " [4 rows x 100 columns],\n",
       "     Amostra 1  Amostra 2  Amostra 3  Amostra 4  Amostra 5  Amostra 6  \\\n",
       " 45        6.0        6.0        6.0        6.0        6.0        6.0   \n",
       " 55        6.5        6.5        6.5        6.5        6.5        6.5   \n",
       " 43        4.0        4.0        4.0        4.0        4.0        4.0   \n",
       " 48        9.0        9.0        9.0        9.0        9.0        9.0   \n",
       " \n",
       "     Amostra 7  Amostra 8  Amostra 9  Amostra 10  ...  Amostra 91  Amostra 92  \\\n",
       " 45        6.0        6.0        6.0         6.0  ...        -6.0        -6.0   \n",
       " 55        6.5        6.5        6.5         6.5  ...        -6.5        -6.5   \n",
       " 43        4.0        4.0        4.0         4.0  ...        -4.0        -4.0   \n",
       " 48        9.0        9.0        9.0         9.0  ...        -9.0        -9.0   \n",
       " \n",
       "     Amostra 93  Amostra 94  Amostra 95  Amostra 96  Amostra 97  Amostra 98  \\\n",
       " 45        -6.0        -6.0        -6.0        -6.0        -6.0        -6.0   \n",
       " 55        -6.5        -6.5        -6.5        -6.5        -6.5        -6.5   \n",
       " 43        -4.0        -4.0        -4.0        -4.0        -4.0        -4.0   \n",
       " 48        -9.0        -9.0        -9.0        -9.0        -9.0        -9.0   \n",
       " \n",
       "     Amostra 99  Amostra 100  \n",
       " 45        -6.0         -6.0  \n",
       " 55        -6.5         -6.5  \n",
       " 43        -4.0         -4.0  \n",
       " 48        -9.0         -9.0  \n",
       " \n",
       " [4 rows x 100 columns],\n",
       "     Amostra 1  Amostra 2  Amostra 3  Amostra 4  Amostra 5  Amostra 6  \\\n",
       " 23        0.0      0.400      0.800      1.200      1.600      2.000   \n",
       " 20       -1.0     -0.900     -0.800     -0.700     -0.600     -0.500   \n",
       " 16        0.0      5.527     10.261     13.526     14.853     14.052   \n",
       " 40        1.0      1.000      1.000      1.000      1.000      1.000   \n",
       " \n",
       "     Amostra 7  Amostra 8  Amostra 9  Amostra 10  ...  Amostra 91  Amostra 92  \\\n",
       " 23      2.400      2.800      3.200       3.600  ...       4.000       4.400   \n",
       " 20     -0.400     -0.300     -0.200      -0.100  ...       0.000       0.100   \n",
       " 16     11.238      6.814      1.413      -4.189  ...       4.189      -1.413   \n",
       " 40      1.000      1.000      1.000       1.000  ...      -1.000      -1.000   \n",
       " \n",
       "     Amostra 93  Amostra 94  Amostra 95  Amostra 96  Amostra 97  Amostra 98  \\\n",
       " 23       4.800       5.200       5.600       6.000       6.400       6.800   \n",
       " 20       0.200       0.300       0.400       0.500       0.600       0.700   \n",
       " 16      -6.814     -11.238     -14.052     -14.853     -13.526     -10.261   \n",
       " 40      -1.000      -1.000      -1.000      -1.000      -1.000      -1.000   \n",
       " \n",
       "     Amostra 99  Amostra 100  \n",
       " 23       7.200          7.6  \n",
       " 20       0.800          0.9  \n",
       " 16      -5.527         -0.0  \n",
       " 40      -1.000         -1.0  \n",
       " \n",
       " [4 rows x 100 columns],\n",
       "     Amostra 1  Amostra 2  Amostra 3  Amostra 4  Amostra 5  Amostra 6  \\\n",
       " 39        0.0      1.050      2.100      3.150      4.200      5.250   \n",
       " 5         0.0      0.761      1.519      2.271      3.014      3.744   \n",
       " 10        0.0      0.101      0.201      0.300      0.396      0.490   \n",
       " 21        0.0      0.200      0.400      0.600      0.800      1.000   \n",
       " \n",
       "     Amostra 7  Amostra 8  Amostra 9  Amostra 10  ...  Amostra 91  Amostra 92  \\\n",
       " 39       6.30      7.350      8.400       9.450  ...      10.500      11.550   \n",
       " 5        4.46      5.158      5.834       6.488  ...      -6.488      -5.834   \n",
       " 10       0.58      0.666      0.748       0.824  ...       1.151       1.176   \n",
       " 21       1.20      1.400      1.600       1.800  ...       2.000       2.200   \n",
       " \n",
       "     Amostra 93  Amostra 94  Amostra 95  Amostra 96  Amostra 97  Amostra 98  \\\n",
       " 39      12.600      13.650      14.700      15.750      16.800      17.850   \n",
       " 5       -5.158      -4.460      -3.744      -3.014      -2.271      -1.519   \n",
       " 10       1.192       1.199       1.198       1.189       1.171       1.145   \n",
       " 21       2.400       2.600       2.800       3.000       3.200       3.400   \n",
       " \n",
       "     Amostra 99  Amostra 100  \n",
       " 39      18.900       19.950  \n",
       " 5       -0.761        0.000  \n",
       " 10       1.111        1.069  \n",
       " 21       3.600        3.800  \n",
       " \n",
       " [4 rows x 100 columns],\n",
       "     Amostra 1  Amostra 2  Amostra 3  Amostra 4  Amostra 5  Amostra 6  \\\n",
       " 9         0.0      1.395      2.785      4.164      5.525      6.865   \n",
       " 30       -1.0     -0.730     -0.460     -0.190      0.080      0.350   \n",
       " 44        5.0      5.000      5.000      5.000      5.000      5.000   \n",
       " 56        7.2      7.200      7.200      7.200      7.200      7.200   \n",
       " \n",
       "     Amostra 7  Amostra 8  Amostra 9  Amostra 10  ...  Amostra 91  Amostra 92  \\\n",
       " 9       8.177      9.455     10.696      11.894  ...     -11.894     -10.696   \n",
       " 30      0.620      0.890     -0.840      -0.570  ...      -0.700      -0.430   \n",
       " 44      5.000      5.000      5.000       5.000  ...      -5.000      -5.000   \n",
       " 56      7.200      7.200      7.200       7.200  ...       7.200       7.200   \n",
       " \n",
       "     Amostra 93  Amostra 94  Amostra 95  Amostra 96  Amostra 97  Amostra 98  \\\n",
       " 9       -9.455      -8.177      -6.865      -5.525      -4.164      -2.785   \n",
       " 30      -0.160       0.110       0.380       0.650       0.920      -0.810   \n",
       " 44      -5.000      -5.000      -5.000      -5.000      -5.000      -5.000   \n",
       " 56       7.200       7.200       7.200       7.200       7.200       7.200   \n",
       " \n",
       "     Amostra 99  Amostra 100  \n",
       " 9       -1.395         0.00  \n",
       " 30      -0.540        -0.27  \n",
       " 44      -5.000        -5.00  \n",
       " 56       7.200         7.20  \n",
       " \n",
       " [4 rows x 100 columns]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_batches = np.array_split(x_treinamento, batch_total)\n",
    "x_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época: 1 erro: 500.797702217102\n",
      "Época: 501 erro: 0.006558258078712065\n",
      "Época: 1001 erro: 0.00016377875249400374\n",
      "Época: 1501 erro: 1.5134807918393278e-05\n",
      "Época: 2001 erro: 1.6033443264618083e-06\n",
      "Época: 2501 erro: 1.5974027700593751e-07\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoca in range(3000):\n",
    "        erro_medio = 0.0\n",
    "        batch_total = int(len(x_treinamento) / batch_size)\n",
    "        x_batches = np.array_split(x_treinamento, batch_total)\n",
    "        y_batches = np.array_split(y_treinamento, batch_total)\n",
    "        for i in range(batch_total):\n",
    "            x_batch, y_batch = x_batches[i], y_batches[i]\n",
    "            _, custo = sess.run([otimizador, erro], feed_dict = {xph: x_batch, yph: y_batch})\n",
    "            erro_medio += custo / batch_total\n",
    "        if epoca % 500 == 0:\n",
    "            print('Época: ' + str(epoca+1) + ' erro: '+ str(erro_medio))\n",
    "    w_final, b_final = sess.run([w,b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'oculta': array([[ 1.0728003 , -1.4121037 , -0.61145055, ...,  0.56054133,\n",
       "          -0.45589295,  1.2453874 ],\n",
       "         [-0.3448142 ,  0.70872086, -1.8321002 , ...,  0.02802613,\n",
       "          -0.91244185, -0.31701994],\n",
       "         [ 1.376421  ,  1.259135  ,  0.7453335 , ..., -0.41263005,\n",
       "           0.35199562,  1.566064  ],\n",
       "         ...,\n",
       "         [-1.2912402 ,  0.08424082, -0.05917333, ...,  1.8374581 ,\n",
       "           0.6558247 , -0.18700925],\n",
       "         [-0.01073581, -1.5602597 , -0.9031249 , ...,  0.68813425,\n",
       "          -0.4821496 ,  1.392388  ],\n",
       "         [-1.237777  , -1.4877526 ,  0.6055094 , ...,  0.420113  ,\n",
       "          -0.61231494,  0.23796734]], dtype=float32),\n",
       "  'saida': array([[ 1.0151395 ,  0.56485844, -0.9612332 ],\n",
       "         [ 0.35467473, -0.71466196,  1.1050595 ],\n",
       "         [-0.48696107, -0.5437292 , -1.6790813 ],\n",
       "         [-0.5300723 , -0.462734  ,  1.2291472 ],\n",
       "         [-0.5022376 ,  0.86861736,  0.6046727 ],\n",
       "         [-0.6397207 , -1.0019268 ,  0.03950358],\n",
       "         [-2.5378377 , -0.31195328,  1.3023498 ],\n",
       "         [-1.3149586 , -0.9933517 , -0.58385116],\n",
       "         [-0.02255319, -1.1072835 , -0.8131434 ],\n",
       "         [-0.01551777,  0.19759174, -0.47300845],\n",
       "         [-1.2638302 ,  0.7327175 ,  0.95692605],\n",
       "         [-1.0251285 , -0.66826016,  0.05515373],\n",
       "         [-0.08006929,  1.3135695 ,  0.39257258],\n",
       "         [-0.11176097,  0.5015563 , -0.5128536 ],\n",
       "         [-1.8778787 ,  0.9448336 ,  1.6192437 ],\n",
       "         [ 0.12445007,  0.09266628, -0.82284516],\n",
       "         [ 0.9295954 , -1.8508666 ,  1.1208526 ],\n",
       "         [ 0.55010253,  1.5746411 , -0.49295267],\n",
       "         [ 0.4096308 ,  0.05857667, -0.2674832 ],\n",
       "         [-0.59791577, -0.44692406, -0.01765453],\n",
       "         [ 0.27605852, -0.63774353, -1.0002038 ],\n",
       "         [-0.1348786 , -0.8767147 ,  1.0129377 ],\n",
       "         [-0.3529146 , -0.29525104, -1.4287009 ],\n",
       "         [ 1.1443864 , -0.44870165,  0.948763  ],\n",
       "         [-0.70223653, -2.0956683 , -0.11353645],\n",
       "         [ 0.21086541,  2.1965275 ,  1.6308206 ],\n",
       "         [-0.09371306, -1.3242891 ,  0.6192057 ],\n",
       "         [ 0.10315265, -0.8814397 ,  1.2106854 ],\n",
       "         [ 0.9828975 ,  1.5066061 ,  1.0881153 ],\n",
       "         [-1.1973264 ,  0.0789383 , -1.1476277 ],\n",
       "         [-0.54291844,  0.6550207 , -0.54015905],\n",
       "         [ 2.1218674 ,  0.32503316, -0.9486529 ],\n",
       "         [ 0.34415498, -1.1545547 ,  0.65281487],\n",
       "         [ 0.93536234,  0.72846085, -0.71206164],\n",
       "         [ 1.1559525 ,  0.11191268, -0.8730465 ],\n",
       "         [-0.25216448,  0.19724256, -0.0530678 ],\n",
       "         [ 0.3082338 , -0.65311307,  0.37511262],\n",
       "         [-0.56102216,  1.6008716 , -0.57050484],\n",
       "         [-0.18189228, -0.17914899,  0.43441957],\n",
       "         [-0.03354356, -0.08250029,  1.0039814 ],\n",
       "         [ 0.2170087 , -1.001376  ,  0.58189356],\n",
       "         [ 0.13908893, -0.06314824, -0.16370003],\n",
       "         [ 0.24635953,  0.28971073,  0.44413963],\n",
       "         [ 0.5420092 ,  0.3066133 , -0.43438333],\n",
       "         [ 0.9842613 ,  0.61472064,  0.13322653],\n",
       "         [ 0.5704198 , -0.9856745 , -0.29968762],\n",
       "         [-1.9640361 , -0.30962577, -0.09268256],\n",
       "         [ 0.11706857,  0.89674634, -1.1044115 ],\n",
       "         [-0.74715513, -0.7193246 , -0.53637147],\n",
       "         [-0.634937  , -0.28008658,  1.2074542 ],\n",
       "         [ 0.4451944 , -0.83613026, -0.22219229]], dtype=float32)},\n",
       " {'oculta': array([-0.7111588 , -0.2983403 ,  2.1705575 ,  0.50859237,  0.6536778 ,\n",
       "          0.13576059, -0.51672804, -0.2257063 ,  0.04025612, -2.0531607 ,\n",
       "         -0.20014492,  0.03346882, -2.3001964 ,  1.1360873 ,  2.3950698 ,\n",
       "          0.8114913 ,  0.0277153 , -1.057291  , -0.3544719 , -0.074095  ,\n",
       "          0.30053282, -0.10364462, -1.4656547 , -1.5538235 ,  1.169179  ,\n",
       "         -1.0992985 , -0.10405982, -1.0297925 , -0.7433772 , -1.3305637 ,\n",
       "         -0.05996107, -0.01486541, -0.47640184,  0.033496  ,  0.4462477 ,\n",
       "          0.00836189, -1.8323784 , -0.59049195, -1.5852271 ,  0.8396014 ,\n",
       "          0.11110023, -1.2166319 , -1.1157273 ,  0.4356688 ,  1.7646055 ,\n",
       "          0.2229646 ,  0.14071493,  1.0842434 ,  0.90100735, -0.55450445,\n",
       "          1.2228097 ], dtype=float32),\n",
       "  'saida': array([-0.83446896, -1.1780721 , -0.8734522 ], dtype=float32)})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_final, b_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsoes_teste = mlp(xph, w_final, b_final)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    r1 = sess.run(previsoes_teste, feed_dict = {xph: x_teste})\n",
    "    r2 = sess.run(tf.nn.softmax(r1))\n",
    "    r3 = sess.run(tf.argmax(r2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-254.87193 ,    7.385465,  244.56656 ],\n",
       "       [ 332.17252 ,   58.894054,  155.46364 ],\n",
       "       [-486.5937  , -510.73184 ,   65.95942 ],\n",
       "       [  60.910828,  388.85947 ,  272.93393 ],\n",
       "       [  23.429855,  126.12574 ,   88.476425],\n",
       "       [ 167.11926 ,   28.249063,   73.244835],\n",
       "       [  29.679184,  170.04097 ,  119.3123  ],\n",
       "       [  28.620682,  -40.567146, -159.33755 ],\n",
       "       [  15.618157,   71.23159 ,   49.93176 ],\n",
       "       [-183.12712 , -195.28099 ,   20.544308],\n",
       "       [-607.9802  , -636.91205 ,   84.125336],\n",
       "       [  20.3051  ,  104.16804 ,   73.05866 ],\n",
       "       [ 299.1549  ,   52.756565,  139.0453  ],\n",
       "       [  14.055787,   60.252743,   42.222813],\n",
       "       [ 209.505   , -416.74252 ,  255.57468 ],\n",
       "       [ 334.48227 ,   59.311214,  156.62901 ],\n",
       "       [-859.91614 , -516.19794 ,  712.0205  ],\n",
       "       [  26.554611,  148.08344 ,  103.89432 ]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0000000e+00, 0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 1.0000000e+00, 4.4576945e-17],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 1.0000000e+00, 9.3072056e-23],\n",
       "       [1.0000000e+00, 8.9558752e-31, 0.0000000e+00],\n",
       "       [7.0370810e-25, 1.0000000e+00, 5.6182459e-10],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00],\n",
       "       [3.7913060e-37, 1.0000000e+00, 3.0858166e-14],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [8.6480190e-21, 1.0000000e+00, 1.4780899e-08],\n",
       "       [9.8219071e-21, 0.0000000e+00, 1.0000000e+00],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00],\n",
       "       [0.0000000e+00, 1.0000000e+00, 6.4403597e-20]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 2, 1, 1, 0, 1, 0, 1, 2, 2, 1, 0, 1, 2, 0, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 2, 1, 1, 0, 1, 2, 1, 2, 2, 1, 0, 1, 2, 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_teste2 = np.argmax(y_teste, 1)\n",
    "y_teste2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8888888888888888"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "taxa_acerto = accuracy_score(y_teste2, r3)\n",
    "taxa_acerto"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
