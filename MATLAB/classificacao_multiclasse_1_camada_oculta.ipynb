{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Douglas\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Douglas\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Douglas\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Douglas\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Douglas\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Douglas\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Douglas\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Douglas\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Douglas\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Douglas\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Douglas\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Douglas\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = base.drop('Forma de onda', axis=1) # atributos previsores\n",
    "y = base.iloc[:,-1] # pegando a ultima coluna para saber qual a classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Amostra 1</th>\n",
       "      <th>Amostra 2</th>\n",
       "      <th>Amostra 3</th>\n",
       "      <th>Amostra 4</th>\n",
       "      <th>Amostra 5</th>\n",
       "      <th>Amostra 6</th>\n",
       "      <th>Amostra 7</th>\n",
       "      <th>Amostra 8</th>\n",
       "      <th>Amostra 9</th>\n",
       "      <th>Amostra 10</th>\n",
       "      <th>...</th>\n",
       "      <th>Amostra 991</th>\n",
       "      <th>Amostra 992</th>\n",
       "      <th>Amostra 993</th>\n",
       "      <th>Amostra 994</th>\n",
       "      <th>Amostra 995</th>\n",
       "      <th>Amostra 996</th>\n",
       "      <th>Amostra 997</th>\n",
       "      <th>Amostra 998</th>\n",
       "      <th>Amostra 999</th>\n",
       "      <th>Amostra 1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.989</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.976</td>\n",
       "      <td>0.970</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.956</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.931</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.998</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.993</td>\n",
       "      <td>0.989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.282</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.057</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>-0.169</td>\n",
       "      <td>-0.282</td>\n",
       "      <td>-0.393</td>\n",
       "      <td>-0.504</td>\n",
       "      <td>-0.612</td>\n",
       "      <td>-0.719</td>\n",
       "      <td>...</td>\n",
       "      <td>1.212</td>\n",
       "      <td>1.120</td>\n",
       "      <td>1.025</td>\n",
       "      <td>0.926</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.613</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.637</td>\n",
       "      <td>3.572</td>\n",
       "      <td>3.501</td>\n",
       "      <td>3.426</td>\n",
       "      <td>3.346</td>\n",
       "      <td>3.260</td>\n",
       "      <td>3.171</td>\n",
       "      <td>3.076</td>\n",
       "      <td>2.978</td>\n",
       "      <td>2.875</td>\n",
       "      <td>...</td>\n",
       "      <td>3.984</td>\n",
       "      <td>3.968</td>\n",
       "      <td>3.946</td>\n",
       "      <td>3.918</td>\n",
       "      <td>3.885</td>\n",
       "      <td>3.846</td>\n",
       "      <td>3.802</td>\n",
       "      <td>3.752</td>\n",
       "      <td>3.697</td>\n",
       "      <td>3.637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.564</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.114</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.339</td>\n",
       "      <td>-0.564</td>\n",
       "      <td>-0.787</td>\n",
       "      <td>-1.008</td>\n",
       "      <td>-1.225</td>\n",
       "      <td>-1.438</td>\n",
       "      <td>...</td>\n",
       "      <td>2.424</td>\n",
       "      <td>2.240</td>\n",
       "      <td>2.049</td>\n",
       "      <td>1.851</td>\n",
       "      <td>1.648</td>\n",
       "      <td>1.439</td>\n",
       "      <td>1.226</td>\n",
       "      <td>1.008</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.559</td>\n",
       "      <td>-0.474</td>\n",
       "      <td>-0.388</td>\n",
       "      <td>-0.301</td>\n",
       "      <td>-0.214</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>-0.038</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.226</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.257</td>\n",
       "      <td>-1.187</td>\n",
       "      <td>-1.115</td>\n",
       "      <td>-1.041</td>\n",
       "      <td>-0.965</td>\n",
       "      <td>-0.887</td>\n",
       "      <td>-0.807</td>\n",
       "      <td>-0.726</td>\n",
       "      <td>-0.643</td>\n",
       "      <td>-0.559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Amostra 1  Amostra 2  Amostra 3  Amostra 4  Amostra 5  Amostra 6  \\\n",
       "0      0.989      0.985      0.981      0.976      0.970      0.963   \n",
       "1      0.282      0.170      0.057     -0.056     -0.169     -0.282   \n",
       "2      3.637      3.572      3.501      3.426      3.346      3.260   \n",
       "3      0.564      0.340      0.114     -0.113     -0.339     -0.564   \n",
       "4     -0.559     -0.474     -0.388     -0.301     -0.214     -0.126   \n",
       "\n",
       "   Amostra 7  Amostra 8  Amostra 9  Amostra 10  ...  Amostra 991  Amostra 992  \\\n",
       "0      0.956      0.949      0.940       0.931  ...        0.997        0.998   \n",
       "1     -0.393     -0.504     -0.612      -0.719  ...        1.212        1.120   \n",
       "2      3.171      3.076      2.978       2.875  ...        3.984        3.968   \n",
       "3     -0.787     -1.008     -1.225      -1.438  ...        2.424        2.240   \n",
       "4     -0.038      0.050      0.138       0.226  ...       -1.257       -1.187   \n",
       "\n",
       "   Amostra 993  Amostra 994  Amostra 995  Amostra 996  Amostra 997  \\\n",
       "0        1.000        1.000        1.000        0.999        0.998   \n",
       "1        1.025        0.926        0.824        0.720        0.613   \n",
       "2        3.946        3.918        3.885        3.846        3.802   \n",
       "3        2.049        1.851        1.648        1.439        1.226   \n",
       "4       -1.115       -1.041       -0.965       -0.887       -0.807   \n",
       "\n",
       "   Amostra 998  Amostra 999  Amostra 1000  \n",
       "0        0.995        0.993         0.989  \n",
       "1        0.504        0.394         0.282  \n",
       "2        3.752        3.697         3.637  \n",
       "3        1.008        0.788         0.564  \n",
       "4       -0.726       -0.643        -0.559  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "onehot = OneHotEncoder(categories = 'auto')\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.values.reshape(-1,1)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = onehot.fit_transform(y).toarray()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_treinamento, x_teste, y_treinamento, y_teste = train_test_split(x, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 1000), (45, 1000), (150, 3), (45, 3))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, x_teste.shape, y.shape, y_teste.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neuronios_entrada = x.shape[1]\n",
    "neuronios_entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "501"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neuronios_oculta = int((neuronios_entrada + y.shape[1])/2)\n",
    "neuronios_oculta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neuronios_saida = y.shape[1]\n",
    "neuronios_saida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'oculta': <tf.Variable 'Variable:0' shape=(1000, 501) dtype=float32_ref>,\n",
       " 'saida': <tf.Variable 'Variable_1:0' shape=(501, 3) dtype=float32_ref>}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = {'oculta': tf.Variable(tf.random_normal([neuronios_entrada, neuronios_oculta])),\n",
    "     'saida': tf.Variable(tf.random_normal([neuronios_oculta, neuronios_saida]))}\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'oculta': <tf.Variable 'Variable_2:0' shape=(501,) dtype=float32_ref>,\n",
       " 'saida': <tf.Variable 'Variable_3:0' shape=(3,) dtype=float32_ref>}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = {'oculta': tf.Variable(tf.random_normal([neuronios_oculta])),\n",
    "     'saida': tf.Variable(tf.random_normal([neuronios_saida]))}\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "xph = tf.placeholder('float', [None, neuronios_entrada])\n",
    "yph = tf.placeholder('float', [None, neuronios_saida])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(x, w, bias):\n",
    "    camada_oculta = tf.add(tf.matmul(x, w['oculta']), b['oculta'])\n",
    "    camada_oculta_ativacao = tf.nn.relu(camada_oculta)\n",
    "    camada_saida = tf.add(tf.matmul(camada_oculta_ativacao, w['saida']), b['saida'])\n",
    "    return camada_saida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = mlp(xph, w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "erro = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = modelo, labels = yph))\n",
    "otimizador = tf.train.AdamOptimizer(learning_rate = 0.0001).minimize(erro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_total = int(len(x_treinamento) / batch_size)\n",
    "batch_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batches = np.array_split(x_treinamento, batch_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época: 1 erro: 2438.7977172851565\n",
      "Época: 501 erro: 9.854802328845835e-06\n",
      "Época: 1001 erro: 7.993385679583298e-07\n",
      "Época: 1501 erro: 6.664873595241262e-08\n",
      "Época: 2001 erro: 4.551626808790843e-09\n",
      "Época: 2501 erro: 0.0\n",
      "Época: 3001 erro: 0.0\n",
      "Época: 3501 erro: 0.0\n",
      "Época: 4001 erro: 0.0\n",
      "Época: 4501 erro: 0.0\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoca in range(5000):\n",
    "        erro_medio = 0.0\n",
    "        batch_total = int(len(x_treinamento) / batch_size)\n",
    "        x_batches = np.array_split(x_treinamento, batch_total)\n",
    "        y_batches = np.array_split(y_treinamento, batch_total)\n",
    "        for i in range(batch_total):\n",
    "            x_batch, y_batch = x_batches[i], y_batches[i]\n",
    "            _, custo = sess.run([otimizador, erro], feed_dict = {xph: x_batch, yph: y_batch})\n",
    "            erro_medio += custo / batch_total\n",
    "        if epoca % 500 == 0:\n",
    "            print('Época: ' + str(epoca+1) + ' erro: '+ str(erro_medio))\n",
    "    w_final, b_final = sess.run([w,b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsoes_teste = mlp(xph, w_final, b_final)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    r1 = sess.run(previsoes_teste, feed_dict = {xph: x_teste})\n",
    "    r2 = sess.run(tf.nn.softmax(r1))\n",
    "    r3 = sess.run(tf.argmax(r2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_teste2 = np.argmax(y_teste, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "taxa_acerto = accuracy_score(y_teste2, r3)\n",
    "taxa_acerto"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
