{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date     price  bedrooms  bathrooms  sqft_living  \\\n",
       "0  7129300520  20141013T000000  221900.0         3       1.00         1180   \n",
       "1  6414100192  20141209T000000  538000.0         3       2.25         2570   \n",
       "2  5631500400  20150225T000000  180000.0         2       1.00          770   \n",
       "3  2487200875  20141209T000000  604000.0         4       3.00         1960   \n",
       "4  1954400510  20150218T000000  510000.0         3       2.00         1680   \n",
       "\n",
       "   sqft_lot  floors  waterfront  view  ...  grade  sqft_above  sqft_basement  \\\n",
       "0      5650     1.0           0     0  ...      7        1180              0   \n",
       "1      7242     2.0           0     0  ...      7        2170            400   \n",
       "2     10000     1.0           0     0  ...      6         770              0   \n",
       "3      5000     1.0           0     0  ...      7        1050            910   \n",
       "4      8080     1.0           0     0  ...      8        1680              0   \n",
       "\n",
       "   yr_built  yr_renovated  zipcode      lat     long  sqft_living15  \\\n",
       "0      1955             0    98178  47.5112 -122.257           1340   \n",
       "1      1951          1991    98125  47.7210 -122.319           1690   \n",
       "2      1933             0    98028  47.7379 -122.233           2720   \n",
       "3      1965             0    98136  47.5208 -122.393           1360   \n",
       "4      1987             0    98074  47.6168 -122.045           1800   \n",
       "\n",
       "   sqft_lot15  \n",
       "0        5650  \n",
       "1        7639  \n",
       "2        8062  \n",
       "3        5000  \n",
       "4        7503  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "base = pd.read_csv('house_prices.csv')\n",
    "base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'date', 'price', 'bedrooms', 'bathrooms', 'sqft_living',\n",
       "       'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'grade',\n",
       "       'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode',\n",
       "       'lat', 'long', 'sqft_living15', 'sqft_lot15'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['price',\n",
       " 'bedrooms',\n",
       " 'bathrooms',\n",
       " 'sqft_living',\n",
       " 'sqft_lot',\n",
       " 'floors',\n",
       " 'waterfront',\n",
       " 'view',\n",
       " 'condition',\n",
       " 'grade',\n",
       " 'sqft_above',\n",
       " 'sqft_basement',\n",
       " 'yr_built',\n",
       " 'yr_renovated',\n",
       " 'zipcode',\n",
       " 'lat',\n",
       " 'long']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colunas_usadas = ['price', 'bedrooms', 'bathrooms', 'sqft_living',\n",
    "       'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'grade',\n",
    "       'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode',\n",
    "       'lat', 'long']\n",
    "colunas_usadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recarregando a base de dados utilizando somente as colunas indicadas\n",
    "\n",
    "base = pd.read_csv('house_prices.csv', usecols = colunas_usadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicação da normalização nos atributos previsores\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler_x = MinMaxScaler()\n",
    "\n",
    "base[['bedrooms', 'bathrooms', 'sqft_living',\n",
    "       'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'grade',\n",
    "       'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode',\n",
    "       'lat', 'long']] = scaler_x.fit_transform(base[['bedrooms', 'bathrooms', 'sqft_living',\n",
    "       'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'grade',\n",
    "       'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode',\n",
    "       'lat', 'long']])\n",
    "\n",
    "scaler_y = MinMaxScaler()\n",
    "base[['price']] = scaler_y.fit_transform(base[['price']]) ## normalizando o Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.019266\n",
       "1        0.060721\n",
       "2        0.013770\n",
       "3        0.069377\n",
       "4        0.057049\n",
       "           ...   \n",
       "21608    0.037377\n",
       "21609    0.042623\n",
       "21610    0.042898\n",
       "21611    0.042623\n",
       "21612    0.032787\n",
       "Name: price, Length: 21613, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = base.drop('price', axis=1) # atributos previsores\n",
    "y = base.price # variável dependente\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bedrooms',\n",
       " 'bathrooms',\n",
       " 'sqft_living',\n",
       " 'sqft_lot',\n",
       " 'floors',\n",
       " 'waterfront',\n",
       " 'view',\n",
       " 'condition',\n",
       " 'grade',\n",
       " 'sqft_above',\n",
       " 'sqft_basement',\n",
       " 'yr_built',\n",
       " 'yr_renovated',\n",
       " 'zipcode',\n",
       " 'lat',\n",
       " 'long']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previsores_colunas = colunas_usadas[1:17]\n",
    "previsores_colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Douglas\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Douglas\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Douglas\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Douglas\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Douglas\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Douglas\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Douglas\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Douglas\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Douglas\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Douglas\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Douglas\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Douglas\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature colunm (recebendo o nome das colunas)\n",
    "colunas = [tf.feature_column.numeric_column(key = c) for c in previsores_colunas] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split # separando base de dados, 70% treinamento e 30% teste\n",
    "x_treinamento, x_teste, y_treinamento, y_teste = train_test_split(x,y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "funcao_treinamento = tf.estimator.inputs.pandas_input_fn(x = x_treinamento, y = y_treinamento,\n",
    "                                                        batch_size = 32, num_epochs = None, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\Douglas\\AppData\\Local\\Temp\\tmpjg1vnu29\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\Douglas\\\\AppData\\\\Local\\\\Temp\\\\tmpjg1vnu29', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000254DEC47DC8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:From C:\\Users\\Douglas\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From C:\\Users\\Douglas\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From C:\\Users\\Douglas\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From C:\\Users\\Douglas\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Entity <bound method _DNNModel.call of <tensorflow_estimator.python.estimator.canned.dnn._DNNModel object at 0x00000254DF0FAC08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method _DNNModel.call of <tensorflow_estimator.python.estimator.canned.dnn._DNNModel object at 0x00000254DF0FAC08>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method _DNNModel.call of <tensorflow_estimator.python.estimator.canned.dnn._DNNModel object at 0x00000254DF0FAC08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method _DNNModel.call of <tensorflow_estimator.python.estimator.canned.dnn._DNNModel object at 0x00000254DF0FAC08>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method DenseFeatures.call of <tensorflow.python.feature_column.feature_column_v2.DenseFeatures object at 0x00000254DF1102C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method DenseFeatures.call of <tensorflow.python.feature_column.feature_column_v2.DenseFeatures object at 0x00000254DF1102C8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method DenseFeatures.call of <tensorflow.python.feature_column.feature_column_v2.DenseFeatures object at 0x00000254DF1102C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method DenseFeatures.call of <tensorflow.python.feature_column.feature_column_v2.DenseFeatures object at 0x00000254DF1102C8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000254DF1311C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000254DF1311C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000254DF1311C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000254DF1311C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000254DF131A88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000254DF131A88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000254DF131A88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000254DF131A88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000254DF131B48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000254DF131B48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000254DF131B48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000254DF131B48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000254DF140448>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000254DF140448>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000254DF140448>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000254DF140448>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From C:\\Users\\Douglas\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\canned\\head.py:437: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Douglas\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\adagrad.py:76: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "WARNING:tensorflow:From C:\\Users\\Douglas\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From C:\\Users\\Douglas\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py:875: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\Douglas\\AppData\\Local\\Temp\\tmpjg1vnu29\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.42487386, step = 1\n",
      "INFO:tensorflow:global_step/sec: 324.528\n",
      "INFO:tensorflow:loss = 0.017487975, step = 101 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 359.837\n",
      "INFO:tensorflow:loss = 0.01641864, step = 201 (0.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 371.72\n",
      "INFO:tensorflow:loss = 0.023714427, step = 301 (0.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 383.114\n",
      "INFO:tensorflow:loss = 0.03672935, step = 401 (0.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 373.106\n",
      "INFO:tensorflow:loss = 0.027153745, step = 501 (0.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 370.345\n",
      "INFO:tensorflow:loss = 0.029613424, step = 601 (0.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 353.323\n",
      "INFO:tensorflow:loss = 0.00943624, step = 701 (0.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.808\n",
      "INFO:tensorflow:loss = 0.030269668, step = 801 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 363.612\n",
      "INFO:tensorflow:loss = 0.011933763, step = 901 (0.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 368.977\n",
      "INFO:tensorflow:loss = 0.0073807873, step = 1001 (0.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 363.609\n",
      "INFO:tensorflow:loss = 0.013001176, step = 1101 (0.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.197\n",
      "INFO:tensorflow:loss = 0.03762773, step = 1201 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 367.62\n",
      "INFO:tensorflow:loss = 0.018897185, step = 1301 (0.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 368.977\n",
      "INFO:tensorflow:loss = 0.007471295, step = 1401 (0.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 367.621\n",
      "INFO:tensorflow:loss = 0.015605344, step = 1501 (0.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 364.937\n",
      "INFO:tensorflow:loss = 0.009096876, step = 1601 (0.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 377.331\n",
      "INFO:tensorflow:loss = 0.0082237385, step = 1701 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 374.505\n",
      "INFO:tensorflow:loss = 0.009176083, step = 1801 (0.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 373.107\n",
      "INFO:tensorflow:loss = 0.03373084, step = 1901 (0.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 377.331\n",
      "INFO:tensorflow:loss = 0.03303572, step = 2001 (0.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 374.504\n",
      "INFO:tensorflow:loss = 0.009276319, step = 2101 (0.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 380.201\n",
      "INFO:tensorflow:loss = 0.023074862, step = 2201 (0.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 377.33\n",
      "INFO:tensorflow:loss = 0.015794761, step = 2301 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 368.977\n",
      "INFO:tensorflow:loss = 0.018110797, step = 2401 (0.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 371.72\n",
      "INFO:tensorflow:loss = 0.044188097, step = 2501 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 368.977\n",
      "INFO:tensorflow:loss = 0.05038551, step = 2601 (0.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 370.342\n",
      "INFO:tensorflow:loss = 0.006042909, step = 2701 (0.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 371.721\n",
      "INFO:tensorflow:loss = 0.023593122, step = 2801 (0.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 370.344\n",
      "INFO:tensorflow:loss = 0.0072591817, step = 2901 (0.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 364.936\n",
      "INFO:tensorflow:loss = 0.019259425, step = 3001 (0.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 368.978\n",
      "INFO:tensorflow:loss = 0.022391483, step = 3101 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 368.976\n",
      "INFO:tensorflow:loss = 0.015385254, step = 3201 (0.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 375.913\n",
      "INFO:tensorflow:loss = 0.0071037216, step = 3301 (0.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 368.976\n",
      "INFO:tensorflow:loss = 0.01436144, step = 3401 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 364.937\n",
      "INFO:tensorflow:loss = 0.007231947, step = 3501 (0.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 368.977\n",
      "INFO:tensorflow:loss = 0.012067826, step = 3601 (0.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 373.107\n",
      "INFO:tensorflow:loss = 0.02590457, step = 3701 (0.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 370.343\n",
      "INFO:tensorflow:loss = 0.022992574, step = 3801 (0.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 367.62\n",
      "INFO:tensorflow:loss = 0.02806871, step = 3901 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 363.61\n",
      "INFO:tensorflow:loss = 0.011991344, step = 4001 (0.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 368.977\n",
      "INFO:tensorflow:loss = 0.008460201, step = 4101 (0.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 374.504\n",
      "INFO:tensorflow:loss = 0.01638231, step = 4201 (0.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 367.62\n",
      "INFO:tensorflow:loss = 0.024657577, step = 4301 (0.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 377.331\n",
      "INFO:tensorflow:loss = 0.053796697, step = 4401 (0.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 366.273\n",
      "INFO:tensorflow:loss = 0.011669575, step = 4501 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 377.331\n",
      "INFO:tensorflow:loss = 0.026599748, step = 4601 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 367.62\n",
      "INFO:tensorflow:loss = 0.015167976, step = 4701 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 375.912\n",
      "INFO:tensorflow:loss = 0.011926092, step = 4801 (0.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 368.977\n",
      "INFO:tensorflow:loss = 0.08524726, step = 4901 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 373.108\n",
      "INFO:tensorflow:loss = 0.013486578, step = 5001 (0.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 367.62\n",
      "INFO:tensorflow:loss = 0.021560278, step = 5101 (0.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.709\n",
      "INFO:tensorflow:loss = 0.010515598, step = 5201 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.424\n",
      "INFO:tensorflow:loss = 0.026972799, step = 5301 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.844\n",
      "INFO:tensorflow:loss = 0.026194993, step = 5401 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 371.72\n",
      "INFO:tensorflow:loss = 0.031291924, step = 5501 (0.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 370.344\n",
      "INFO:tensorflow:loss = 0.010204508, step = 5601 (0.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 375.913\n",
      "INFO:tensorflow:loss = 0.026924223, step = 5701 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 381.651\n",
      "INFO:tensorflow:loss = 0.013544083, step = 5801 (0.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 375.912\n",
      "INFO:tensorflow:loss = 0.010686974, step = 5901 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 375.913\n",
      "INFO:tensorflow:loss = 0.01815218, step = 6001 (0.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 374.503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.008876095, step = 6101 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 368.977\n",
      "INFO:tensorflow:loss = 0.005803196, step = 6201 (0.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 370.344\n",
      "INFO:tensorflow:loss = 0.011010607, step = 6301 (0.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 378.759\n",
      "INFO:tensorflow:loss = 0.012180703, step = 6401 (0.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 386.072\n",
      "INFO:tensorflow:loss = 0.012767, step = 6501 (0.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 377.331\n",
      "INFO:tensorflow:loss = 0.035863597, step = 6601 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 373.107\n",
      "INFO:tensorflow:loss = 0.0024060435, step = 6701 (0.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 373.107\n",
      "INFO:tensorflow:loss = 0.005740879, step = 6801 (0.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 378.76\n",
      "INFO:tensorflow:loss = 0.008898915, step = 6901 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 377.331\n",
      "INFO:tensorflow:loss = 0.012668825, step = 7001 (0.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 371.72\n",
      "INFO:tensorflow:loss = 0.023239467, step = 7101 (0.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 374.504\n",
      "INFO:tensorflow:loss = 0.013294682, step = 7201 (0.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 368.976\n",
      "INFO:tensorflow:loss = 0.009459945, step = 7301 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 380.201\n",
      "INFO:tensorflow:loss = 0.0059429696, step = 7401 (0.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 380.193\n",
      "INFO:tensorflow:loss = 0.010873621, step = 7501 (0.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 381.658\n",
      "INFO:tensorflow:loss = 0.015114887, step = 7601 (0.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 375.913\n",
      "INFO:tensorflow:loss = 0.003878169, step = 7701 (0.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 375.913\n",
      "INFO:tensorflow:loss = 0.004841103, step = 7801 (0.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 359.685\n",
      "INFO:tensorflow:loss = 0.019874115, step = 7901 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 354.584\n",
      "INFO:tensorflow:loss = 0.019706633, step = 8001 (0.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.844\n",
      "INFO:tensorflow:loss = 0.01474655, step = 8101 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 360.979\n",
      "INFO:tensorflow:loss = 0.006667962, step = 8201 (0.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 362.299\n",
      "INFO:tensorflow:loss = 0.018752161, step = 8301 (0.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 364.937\n",
      "INFO:tensorflow:loss = 0.008345029, step = 8401 (0.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 363.61\n",
      "INFO:tensorflow:loss = 0.008466113, step = 8501 (0.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 377.328\n",
      "INFO:tensorflow:loss = 0.0069913985, step = 8601 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 374.506\n",
      "INFO:tensorflow:loss = 0.005092463, step = 8701 (0.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 378.76\n",
      "INFO:tensorflow:loss = 0.011971777, step = 8801 (0.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 353.33\n",
      "INFO:tensorflow:loss = 0.012483234, step = 8901 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 374.505\n",
      "INFO:tensorflow:loss = 0.026537765, step = 9001 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 370.343\n",
      "INFO:tensorflow:loss = 0.010727568, step = 9101 (0.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 370.343\n",
      "INFO:tensorflow:loss = 0.009463446, step = 9201 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 374.505\n",
      "INFO:tensorflow:loss = 0.027628448, step = 9301 (0.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 374.504\n",
      "INFO:tensorflow:loss = 0.01207673, step = 9401 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 367.621\n",
      "INFO:tensorflow:loss = 0.013108827, step = 9501 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 375.912\n",
      "INFO:tensorflow:loss = 0.056993198, step = 9601 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 370.343\n",
      "INFO:tensorflow:loss = 0.0066911937, step = 9701 (0.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 374.505\n",
      "INFO:tensorflow:loss = 0.009820839, step = 9801 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 378.759\n",
      "INFO:tensorflow:loss = 0.0032168732, step = 9901 (0.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 378.76\n",
      "INFO:tensorflow:loss = 0.008940044, step = 10001 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 374.504\n",
      "INFO:tensorflow:loss = 0.020099942, step = 10101 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 375.913\n",
      "INFO:tensorflow:loss = 0.01197009, step = 10201 (0.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 378.76\n",
      "INFO:tensorflow:loss = 0.008922622, step = 10301 (0.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 375.912\n",
      "INFO:tensorflow:loss = 0.016071059, step = 10401 (0.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 373.108\n",
      "INFO:tensorflow:loss = 0.004777286, step = 10501 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 370.342\n",
      "INFO:tensorflow:loss = 0.006117238, step = 10601 (0.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 370.344\n",
      "INFO:tensorflow:loss = 0.0060835844, step = 10701 (0.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 371.72\n",
      "INFO:tensorflow:loss = 0.007847402, step = 10801 (0.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 363.61\n",
      "INFO:tensorflow:loss = 0.00527341, step = 10901 (0.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 354.584\n",
      "INFO:tensorflow:loss = 0.018951952, step = 11001 (0.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.707\n",
      "INFO:tensorflow:loss = 0.008739534, step = 11101 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.458\n",
      "INFO:tensorflow:loss = 0.015562193, step = 11201 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.273\n",
      "INFO:tensorflow:loss = 0.00625858, step = 11301 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 367.62\n",
      "INFO:tensorflow:loss = 0.01835062, step = 11401 (0.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 371.719\n",
      "INFO:tensorflow:loss = 0.012272644, step = 11501 (0.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 381.652\n",
      "INFO:tensorflow:loss = 0.007183982, step = 11601 (0.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 374.504\n",
      "INFO:tensorflow:loss = 0.011783388, step = 11701 (0.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 384.587\n",
      "INFO:tensorflow:loss = 0.002007511, step = 11801 (0.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 373.107\n",
      "INFO:tensorflow:loss = 0.037106503, step = 11901 (0.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 373.107\n",
      "INFO:tensorflow:loss = 0.03801405, step = 12001 (0.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 373.107\n",
      "INFO:tensorflow:loss = 0.013371344, step = 12101 (0.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 373.106\n",
      "INFO:tensorflow:loss = 0.009414095, step = 12201 (0.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 370.343\n",
      "INFO:tensorflow:loss = 0.017068662, step = 12301 (0.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 377.33\n",
      "INFO:tensorflow:loss = 0.010617776, step = 12401 (0.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 366.275\n",
      "INFO:tensorflow:loss = 0.012777779, step = 12501 (0.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 374.504\n",
      "INFO:tensorflow:loss = 0.006211555, step = 12601 (0.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 373.107\n",
      "INFO:tensorflow:loss = 0.0074699945, step = 12701 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 370.343\n",
      "INFO:tensorflow:loss = 0.007849767, step = 12801 (0.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 374.504\n",
      "INFO:tensorflow:loss = 0.019075451, step = 12901 (0.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 367.62\n",
      "INFO:tensorflow:loss = 0.013208542, step = 13001 (0.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 374.505\n",
      "INFO:tensorflow:loss = 0.010823309, step = 13101 (0.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 377.331\n",
      "INFO:tensorflow:loss = 0.01191525, step = 13201 (0.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 380.2\n",
      "INFO:tensorflow:loss = 0.016105806, step = 13301 (0.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 364.938\n",
      "INFO:tensorflow:loss = 0.0065933405, step = 13401 (0.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 374.503\n",
      "INFO:tensorflow:loss = 0.010206182, step = 13501 (0.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 353.331\n",
      "INFO:tensorflow:loss = 0.008956263, step = 13601 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 363.608\n",
      "INFO:tensorflow:loss = 0.020048557, step = 13701 (0.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 371.721\n",
      "INFO:tensorflow:loss = 0.019640021, step = 13801 (0.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 373.107\n",
      "INFO:tensorflow:loss = 0.0059231045, step = 13901 (0.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 371.72\n",
      "INFO:tensorflow:loss = 0.0161784, step = 14001 (0.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 373.107\n",
      "INFO:tensorflow:loss = 0.0129497, step = 14101 (0.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.019556234, step = 14201 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 371.721\n",
      "INFO:tensorflow:loss = 0.013175366, step = 14301 (0.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 368.976\n",
      "INFO:tensorflow:loss = 0.02727636, step = 14401 (0.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 332.201\n",
      "INFO:tensorflow:loss = 0.011764854, step = 14501 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.995\n",
      "INFO:tensorflow:loss = 0.011847483, step = 14601 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 377.332\n",
      "INFO:tensorflow:loss = 0.009650314, step = 14701 (0.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.623\n",
      "INFO:tensorflow:loss = 0.0053686397, step = 14801 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.677\n",
      "INFO:tensorflow:loss = 0.025708422, step = 14901 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 368.977\n",
      "INFO:tensorflow:loss = 0.014737321, step = 15001 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.424\n",
      "INFO:tensorflow:loss = 0.003922482, step = 15101 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.844\n",
      "INFO:tensorflow:loss = 0.015883863, step = 15201 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 364.936\n",
      "INFO:tensorflow:loss = 0.029051589, step = 15301 (0.274 sec)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-423dc6afc428>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mregressor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDNNRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_units\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_columns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolunas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mregressor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfuncao_treinamento\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 367\u001b[1;33m       \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    368\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loss for final step: %s.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1156\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1157\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1158\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1160\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1190\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[0;32m   1191\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1192\u001b[1;33m                                              saving_listeners)\n\u001b[0m\u001b[0;32m   1193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1194\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_train_model_distributed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_with_estimator_spec\u001b[1;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[0;32m   1482\u001b[0m       \u001b[0many_step_done\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1483\u001b[0m       \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1484\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1485\u001b[0m         \u001b[0many_step_done\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1486\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0many_step_done\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    752\u001b[0m         \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m         \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 754\u001b[1;33m         run_metadata=run_metadata)\n\u001b[0m\u001b[0;32m    755\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1250\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1251\u001b[0m             \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1252\u001b[1;33m             run_metadata=run_metadata)\n\u001b[0m\u001b[0;32m   1253\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1254\u001b[0m         logging.info(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1336\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1337\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1338\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1339\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1340\u001b[0m       \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1409\u001b[0m         \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1410\u001b[0m         \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1411\u001b[1;33m         run_metadata=run_metadata)\n\u001b[0m\u001b[0;32m   1412\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1413\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1168\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1169\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1171\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_with_hooks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 950\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    951\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1171\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1173\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1174\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1350\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1354\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1355\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1356\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1357\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1339\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1341\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1427\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1429\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1431\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "regressor = tf.estimator.DNNRegressor(hidden_units = [8, 8, 8], feature_columns = colunas)\n",
    "regressor.train(input_fn = funcao_treinamento, steps = 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funcao_previsao = tf.estimator.inputs.pandas_input_fn(x = x_teste, shuffle = False)\n",
    "previsoes = regressor.predict(input_fn = funcao_previsao)\n",
    "list(previsoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valores_previsoes = []\n",
    "for p in regressor.predict(input_fn = funcao_previsao):\n",
    "    valores_previsoes.append(p['predictions'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valores_previsoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "valores_previsoes = np.asarray(valores_previsoes).reshape(-1,1)\n",
    "valores_previsoes = scaler_y.inverse_transform(valores_previsoes)\n",
    "valores_previsoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_teste2 = y_teste.values.reshape(-1,1)\n",
    "y_teste2 = scaler_y.inverse_transform(y_teste2)\n",
    "y_teste2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mae = mean_absolute_error(y_teste2, valores_previsoes)\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se observa em relação a outro exemplo sem usar redes neurais que o valor do erro foi de 130k\n",
    "\n",
    "# ganho considerável"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
