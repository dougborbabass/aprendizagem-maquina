{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist/train-images-idx3-ubyte.gz\n",
      "Extracting mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('mnist/', one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_treinamento = mnist.train.images\n",
    "x_treinamento.shape ## 55k imagens no formato 28x28 (por isso 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 10)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_treinamento = mnist.train.labels\n",
    "y_treinamento.shape ## 55k images saidas de 0 a 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_teste = mnist.test.images\n",
    "y_teste = mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Classe: 7')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.imshow(x_treinamento[0].reshape(28,28), cmap = 'gray')\n",
    "plt.title('Classe: ' + str(np.argmax(y_treinamento[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 784)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_batch, y_batch = mnist.train.next_batch(64)\n",
    "x_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### inicio da rede ############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neuronios_entrada = x_treinamento.shape[1]\n",
    "neuronios_entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "397"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Fórumula para definir numero de neuronios da camada ocula\n",
    "## = n de atributos somado com a qtd de classes e divide por 2\n",
    "\n",
    "neuronios_oculta1 = int((x_treinamento.shape[1] + y_treinamento.shape[1])/2)\n",
    "neuronios_oculta1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neuronios_oculta2 = neuronios_oculta1\n",
    "neuronios_oculta3 = neuronios_oculta1\n",
    "neuronios_saida = y_treinamento.shape[1]\n",
    "neuronios_saida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "## estrutura de neuronios\n",
    "\n",
    "## 784 -> 397 -> 397 -> 397 -> 10\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = {'oculta1': tf.Variable(tf.random_normal([neuronios_entrada, neuronios_oculta1])),\n",
    "     'oculta2': tf.Variable(tf.random_normal([neuronios_oculta1, neuronios_oculta2])),\n",
    "     'oculta3': tf.Variable(tf.random_normal([neuronios_oculta2, neuronios_oculta3])),\n",
    "     'saida': tf.Variable(tf.random_normal([neuronios_oculta3, neuronios_saida]))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = {'oculta1': tf.Variable(tf.random_normal([neuronios_oculta1])),\n",
    "     'oculta2': tf.Variable(tf.random_normal([neuronios_oculta2])),\n",
    "     'oculta3': tf.Variable(tf.random_normal([neuronios_oculta3])),\n",
    "     'saida': tf.Variable(tf.random_normal([neuronios_saida]))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "xph = tf.placeholder('float', [None, neuronios_entrada])\n",
    "yph = tf.placeholder('float', [None, neuronios_saida])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcSomatorioAtivacao(x, w, bias):\n",
    "    camada_oculta1 = tf.nn.relu(tf.add(tf.matmul(x, w['oculta1']), b['oculta1']))\n",
    "    camada_oculta2 = tf.nn.relu(tf.add(tf.matmul(camada_oculta1, w['oculta2']), b['oculta2']))\n",
    "    camada_oculta3 = tf.nn.relu(tf.add(tf.matmul(camada_oculta2, w['oculta3']), b['oculta3']))\n",
    "    camada_saida = tf.add(tf.matmul(camada_oculta3, w['saida']), b['saida'])\n",
    "    return camada_saida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = calcSomatorioAtivacao(xph, w, b)\n",
    "erro = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = modelo, labels = yph))\n",
    "otimizador = tf.train.AdamOptimizer(learning_rate = 0.0001).minimize(erro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsoes = tf.nn.softmax(modelo)\n",
    "previsoes_corretas = tf.equal(tf.argmax(previsoes, 1), tf.argmax(yph, 1))\n",
    "taxa_acerto = tf.reduce_mean(tf.cast(previsoes_corretas, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época: 1 erro: 35812.785 taxa de acerto na epoca: [0.1328125]\n",
      "Época: 101 erro: 13969.506 taxa de acerto na epoca: [0.1796875]\n",
      "Época: 201 erro: 8653.807 taxa de acerto na epoca: [0.3515625]\n",
      "Época: 301 erro: 6531.0664 taxa de acerto na epoca: [0.4921875]\n",
      "Época: 401 erro: 5141.751 taxa de acerto na epoca: [0.546875]\n",
      "Época: 501 erro: 4925.0244 taxa de acerto na epoca: [0.5703125]\n",
      "Época: 601 erro: 3549.9705 taxa de acerto na epoca: [0.6171875]\n",
      "Época: 701 erro: 2714.1292 taxa de acerto na epoca: [0.6875]\n",
      "Época: 801 erro: 3186.5986 taxa de acerto na epoca: [0.6953125]\n",
      "Época: 901 erro: 2074.711 taxa de acerto na epoca: [0.75]\n",
      "Época: 1001 erro: 1970.9403 taxa de acerto na epoca: [0.7421875]\n",
      "Época: 1101 erro: 1637.7314 taxa de acerto na epoca: [0.7890625]\n",
      "Época: 1201 erro: 1740.8696 taxa de acerto na epoca: [0.7734375]\n",
      "Época: 1301 erro: 1805.0352 taxa de acerto na epoca: [0.8046875]\n",
      "Época: 1401 erro: 2001.8206 taxa de acerto na epoca: [0.78125]\n",
      "Época: 1501 erro: 1566.6575 taxa de acerto na epoca: [0.828125]\n",
      "Época: 1601 erro: 1656.8494 taxa de acerto na epoca: [0.7578125]\n",
      "Época: 1701 erro: 1079.3274 taxa de acerto na epoca: [0.8359375]\n",
      "Época: 1801 erro: 1118.5051 taxa de acerto na epoca: [0.8359375]\n",
      "Época: 1901 erro: 1359.4641 taxa de acerto na epoca: [0.8515625]\n",
      "Época: 2001 erro: 935.7143 taxa de acerto na epoca: [0.8671875]\n",
      "Época: 2101 erro: 1270.9521 taxa de acerto na epoca: [0.859375]\n",
      "Época: 2201 erro: 1326.8545 taxa de acerto na epoca: [0.84375]\n",
      "Época: 2301 erro: 1024.803 taxa de acerto na epoca: [0.8359375]\n",
      "Época: 2401 erro: 627.08264 taxa de acerto na epoca: [0.8984375]\n",
      "Época: 2501 erro: 773.03845 taxa de acerto na epoca: [0.875]\n",
      "Época: 2601 erro: 797.4083 taxa de acerto na epoca: [0.9140625]\n",
      "Época: 2701 erro: 876.6644 taxa de acerto na epoca: [0.8515625]\n",
      "Época: 2801 erro: 1228.821 taxa de acerto na epoca: [0.8203125]\n",
      "Época: 2901 erro: 569.4052 taxa de acerto na epoca: [0.8671875]\n",
      "Época: 3001 erro: 338.46426 taxa de acerto na epoca: [0.9296875]\n",
      "Época: 3101 erro: 1070.3972 taxa de acerto na epoca: [0.890625]\n",
      "Época: 3201 erro: 1006.0515 taxa de acerto na epoca: [0.8984375]\n",
      "Época: 3301 erro: 577.4918 taxa de acerto na epoca: [0.90625]\n",
      "Época: 3401 erro: 359.04086 taxa de acerto na epoca: [0.9375]\n",
      "Época: 3501 erro: 994.31757 taxa de acerto na epoca: [0.859375]\n",
      "Época: 3601 erro: 1077.1619 taxa de acerto na epoca: [0.8828125]\n",
      "Época: 3701 erro: 1081.8469 taxa de acerto na epoca: [0.8359375]\n",
      "Época: 3801 erro: 1117.2075 taxa de acerto na epoca: [0.84375]\n",
      "Época: 3901 erro: 525.1561 taxa de acerto na epoca: [0.90625]\n",
      "Época: 4001 erro: 617.166 taxa de acerto na epoca: [0.921875]\n",
      "Época: 4101 erro: 411.0135 taxa de acerto na epoca: [0.8671875]\n",
      "Época: 4201 erro: 199.50063 taxa de acerto na epoca: [0.9296875]\n",
      "Época: 4301 erro: 461.30905 taxa de acerto na epoca: [0.8828125]\n",
      "Época: 4401 erro: 494.60736 taxa de acerto na epoca: [0.9296875]\n",
      "Época: 4501 erro: 544.1841 taxa de acerto na epoca: [0.9296875]\n",
      "Época: 4601 erro: 582.9562 taxa de acerto na epoca: [0.8984375]\n",
      "Época: 4701 erro: 789.88837 taxa de acerto na epoca: [0.8671875]\n",
      "Época: 4801 erro: 593.45667 taxa de acerto na epoca: [0.8671875]\n",
      "Época: 4901 erro: 177.02362 taxa de acerto na epoca: [0.953125]\n",
      "Treinamento concluído\n",
      "[ True  True  True ...  True  True  True]\n",
      "Taxa de acerto: 0.8932\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epocas in range(5000):\n",
    "        x_batch, y_batch = mnist.train.next_batch(128)\n",
    "        _, custo = sess.run([otimizador, erro], feed_dict = {xph: x_batch, yph: y_batch})\n",
    "        if epocas % 100 == 0:\n",
    "            acc = sess.run([taxa_acerto], feed_dict = {xph: x_batch, yph: y_batch})\n",
    "            print('Época: ' + str(epocas + 1) + ' erro: ' + str(custo) + ' taxa de acerto na epoca: ' + str(acc))\n",
    "    print('Treinamento concluído')\n",
    "    print(sess.run(previsoes_corretas, feed_dict = {xph: x_teste, yph:y_teste}))\n",
    "    print('Taxa de acerto: ' + str(sess.run(taxa_acerto, feed_dict = {xph: x_teste, yph:y_teste})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
